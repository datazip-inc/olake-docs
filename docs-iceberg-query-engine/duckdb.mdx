---
title: DuckDB v1.3+
description: A light-weight, read-only analytics engine for Iceberg with SQL time travel, external file caching, and REST catalog support
hide_table_of_contents: true
---

import { QueryEngineLayout } from '@site/src/components/Iceberg/QueryEngineLayout';
import {
  //   DatabaseIcon,
  BoltIcon,
  ShieldCheckIcon,
  ClockIcon,
  CloudIcon,
  CubeIcon,
  ExclamationTriangleIcon,
  ChartBarIcon
} from '@heroicons/react/24/outline';

export const duckdbFeatures = [
  {
    title: "Catalog Support",
    chip: "Partial Support",
    description: "Hadoop (file-system) and Iceberg REST catalogs supported via rest option with bearer/OAuth tokens; no native Hive/Glue catalog yet",
    icon: <BoltIcon className="w-6 h-6" />,
    color: "orange",
    score: 65,
    details: {
      title: "Flexible Catalog Integration",
      description: "DuckDB provides support for essential catalog types while maintaining simplicity, with strong REST catalog authentication capabilities.",
      overviewContent: {
        strengths: [
          "Simple file-system catalog support via direct paths",
          "REST catalog integration with OAuth2 and bearer token authentication",
          "Built-in support for moved table paths with allow_moved_paths flag",
          "Session-based catalog configuration and token management",
          "Automatic REST catalog refresh with configurable intervals"
        ],
        limitations: [
          "No native Hive Metastore or AWS Glue catalog support",
          "Must proxy Hive/Glue catalogs through REST implementations",
          "Limited to catalog types supported by the extension",
          "Single catalog per session limitations"
        ],
        bestFor: [
          "Direct file-system based data lake exploration",
          "Modern REST catalog deployments with cloud providers",
          "Ad-hoc analytics on laptop or local environments",
          "Prototyping and development workflows"
        ]
      },
      technicalSpecs: [
        {
          category: "Supported Catalog Types",
          items: [
            { label: "Hadoop (File-system)", value: "Direct paths", status: "available" },
            { label: "REST Catalog", value: "With auth tokens", status: "available" },
            { label: "Hive Metastore", value: "Via REST proxy only", status: "limited" },
            { label: "AWS Glue", value: "Via REST proxy only", status: "limited" },
            { label: "Custom Catalogs", value: "Not supported", status: "unavailable" }
          ]
        },
        {
          category: "Authentication Features",
          items: [
            { label: "Bearer Tokens", value: "rest_auth_token parameter", status: "available" },
            { label: "OAuth2", value: "Through REST auth", status: "available" },
            { label: "S3 Credentials", value: "Via httpfs extension", status: "available" },
            { label: "Session-based Auth", value: "Per-session tokens", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Iceberg Extension Overview", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/overview.html", type: "docs" },
        { label: "Iceberg REST Catalogs", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/iceberg_rest_catalogs.html", type: "docs" }
      ]
    }
  },
  {
    title: "Read-only Analytics Excellence",
    chip: "Full Support",
    description: "Full SELECT support with predicate evaluation, manifest pruning and external file-cache to avoid re-downloading S3/GCS objects",
    icon: <ChartBarIcon className="w-6 h-6" />,
    color: "green",
    score: 95,
    details: {
      title: "Optimized Analytical Queries",
      description: "DuckDB excels at read-only analytics with advanced optimizations for cloud storage and query performance.",
      overviewContent: {
        strengths: [
          "Full SQL SELECT support with complex query capabilities",
          "Advanced predicate pushdown and manifest pruning",
          "External file-cache for S3/GCS objects reduces cold-scan latency",
          "Cost-based query optimization using metadata statistics",
          "Efficient single-node execution for moderate-sized datasets"
        ],
        limitations: [
          "No write capabilities (INSERT/CREATE TABLE AS ICEBERG)",
          "Single-node execution limits scale for very large datasets",
          "Partition pruning not yet fully cost-based for complex predicates",
          "Large lake queries constrained by local resources"
        ],
        bestFor: [
          "Interactive data exploration and ad-hoc analytics",
          "Laptop-based data science and development",
          "Prototyping and testing data transformations",
          "Small to medium-scale analytical workloads"
        ]
      },
      technicalSpecs: [
        {
          category: "Query Capabilities",
          items: [
            { label: "SELECT Operations", value: "Full SQL support", status: "available" },
            { label: "Predicate Pushdown", value: "Automatic", status: "available" },
            { label: "Manifest Pruning", value: "Enabled", status: "available" },
            { label: "Join Operations", value: "Full support", status: "available" },
            { label: "Aggregations", value: "Complete", status: "available" }
          ]
        },
        {
          category: "Performance Features",
          items: [
            { label: "External File Cache", value: "Configurable size", status: "available" },
            { label: "Cold-scan Optimization", value: "50% latency reduction", status: "available" },
            { label: "Cost-based Optimization", value: "Metadata-driven", status: "available" },
            { label: "Parallel Processing", value: "Single-node", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Iceberg Extension Overview", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/overview.html", type: "docs" },
        { label: "DuckLake Performance", url: "https://duckdb.org/2025/05/27/ducklake.html", type: "blog" }
      ]
    }
  },
  {
    title: "Advanced Time Travel",
    chip: "SQL Syntax",
    description: "Convenient SQL syntax: SELECT * FROM tbl AT (VERSION => 314159) or AT (TIMESTAMP => '2025-05-01 10:15:00'); older function-style still works",
    icon: <ClockIcon className="w-6 h-6" />,
    color: "blue",
    score: 100,
    details: {
      title: "Intuitive Time Travel Capabilities",
      description: "DuckDB 1.3 introduces elegant SQL syntax for time travel operations, making point-in-time queries simple and intuitive.",
      overviewContent: {
        strengths: [
          "Native SQL AT syntax for time travel operations",
          "Support for both version-based and timestamp-based queries",
          "Backward compatibility with function-style parameters",
          "Seamless integration with existing query patterns",
          "No need to pass full metadata filenames manually"
        ],
        limitations: [
          "Time travel limited to available snapshots in metadata",
          "Performance depends on snapshot retention policies",
          "Cannot time travel beyond oldest available snapshot"
        ],
        bestFor: [
          "Data auditing and compliance scenarios",
          "Historical data analysis and comparison",
          "Data quality validation at specific points",
          "Debugging data pipeline issues"
        ]
      },
      technicalSpecs: [
        {
          category: "SQL Time Travel Syntax",
          items: [
            { label: "Version-based", value: "AT (VERSION => 314159)", status: "available" },
            { label: "Timestamp-based", value: "AT (TIMESTAMP => '2025-05-01 10:15:00')", status: "available" },
            { label: "Function-style", value: "snapshot_from_id/timestamp", status: "available" },
            { label: "Branch/Tag Support", value: "Not yet available", status: "unavailable" }
          ]
        },
        {
          category: "Metadata Operations",
          items: [
            { label: "iceberg_snapshots()", value: "Current snapshot first", status: "available" },
            { label: "Summary JSON", value: "Quick diffing support", status: "available" },
            { label: "iceberg_metadata()", value: "File stats for planner", status: "available" },
            { label: "Snapshot Navigation", value: "Simple and intuitive", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Iceberg Extension Overview", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/overview.html", type: "docs" }
      ]
    }
  },
  {
    title: "External File Caching",
    chip: "Performance Boost",
    description: "External file-cache via SET s3_cache_size='4GB'; halves cold-scan latency for Iceberg on S3/GCS with intelligent object reuse",
    icon: <CloudIcon className="w-6 h-6" />,
    color: "purple",
    score: 90,
    details: {
      title: "Intelligent Cloud Storage Optimization",
      description: "DuckDB's external file caching dramatically improves performance for cloud-based Iceberg tables by avoiding redundant downloads.",
      overviewContent: {
        strengths: [
          "Configurable cache size for optimal memory usage",
          "50% reduction in cold-scan latency for cloud storage",
          "Intelligent object reuse between queries",
          "Automatic cache management and eviction",
          "Support for both S3 and Google Cloud Storage"
        ],
        limitations: [
          "Cache is session-based and not persistent across restarts",
          "Memory usage increases with cache size configuration",
          "Cache effectiveness depends on query patterns",
          "Limited to single-node cache management"
        ],
        bestFor: [
          "Repeated queries on the same Iceberg tables",
          "Interactive analytics with iterative exploration",
          "Cloud-based data lakes with high network latency",
          "Development and testing environments"
        ]
      },
      technicalSpecs: [
        {
          category: "Cache Configuration",
          items: [
            { label: "Cache Size Setting", value: "SET s3_cache_size='4GB'", status: "available" },
            { label: "Supported Storage", value: "S3, GCS", status: "available" },
            { label: "Cache Management", value: "Automatic", status: "available" },
            { label: "Performance Gain", value: "~50% latency reduction", status: "available" }
          ]
        },
        {
          category: "Storage Support",
          items: [
            { label: "Amazon S3", value: "Full support", status: "available" },
            { label: "Google Cloud Storage", value: "Full support", status: "available" },
            { label: "Azure Blob Storage", value: "Via httpfs", status: "available" },
            { label: "Local File System", value: "No caching needed", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "DuckLake Performance Blog", url: "https://duckdb.org/2025/05/27/ducklake.html", type: "blog" },
        { label: "Iceberg Extension Overview", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/overview.html", type: "docs" }
      ]
    }
  },
  {
    title: "Format Compatibility",
    chip: "Parquet Only",
    description: "Parquet remains the only supported data-file format; Avro/ORC data files are ignored, limiting compatibility with mixed-format tables",
    icon: <CubeIcon className="w-6 h-6" />,
    color: "orange",
    score: 60,
    details: {
      title: "Parquet-focused Data Access",
      description: "DuckDB's Iceberg support is optimized for Parquet files, which covers the majority of modern Iceberg deployments but may limit legacy compatibility.",
      overviewContent: {
        strengths: [
          "Excellent Parquet support with native optimizations",
          "Full compatibility with modern Iceberg best practices",
          "Optimized columnar processing for analytical workloads",
          "Native DuckDB Parquet performance benefits",
          "Support for Parquet-specific features and compression"
        ],
        limitations: [
          "Avro data files are completely ignored",
          "ORC data files are not supported",
          "Mixed-format tables cannot be fully read",
          "Legacy Iceberg tables with non-Parquet files are limited"
        ],
        bestFor: [
          "Modern Iceberg deployments using Parquet exclusively",
          "Analytical workloads optimized for columnar access",
          "Data lakes following current best practices",
          "Performance-critical read-only analytics"
        ]
      },
      technicalSpecs: [
        {
          category: "Supported Formats",
          items: [
            { label: "Parquet", value: "Full support", status: "available" },
            { label: "Avro", value: "Files ignored", status: "unavailable" },
            { label: "ORC", value: "Not supported", status: "unavailable" },
            { label: "Mixed Tables", value: "Partial reads only", status: "limited" }
          ]
        },
        {
          category: "Parquet Features",
          items: [
            { label: "Columnar Processing", value: "Optimized", status: "available" },
            { label: "Compression Support", value: "All formats", status: "available" },
            { label: "Predicate Pushdown", value: "Native", status: "available" },
            { label: "Schema Evolution", value: "Read-compatible", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Troubleshooting - Format Limitations", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/troubleshooting.html", type: "docs" },
        { label: "DuckDB Parquet Support", url: "https://duckdb.org/docs/stable/sql/statements/export.html", type: "docs" }
      ]
    }
  },
  {
    title: "Metadata Operations",
    chip: "Helper Functions",
    description: "iceberg_snapshots() returns current snapshot first with summary JSON; iceberg_metadata() exposes file-size/row-count stats for planner optimization",
    icon: <BoltIcon className="w-6 h-6" />,
    color: "green",
    score: 85,
    details: {
      title: "Rich Metadata Introspection",
      description: "DuckDB provides comprehensive metadata helper functions that enable deep introspection and optimization of Iceberg tables.",
      overviewContent: {
        strengths: [
          "Current snapshot returned first for convenience",
          "Summary JSON column for quick snapshot diffing",
          "File-size and row-count statistics for query planning",
          "Cost-based optimization using metadata statistics",
          "Simple function-based API for metadata access"
        ],
        limitations: [
          "Metadata functions are read-only",
          "No modification of table metadata possible",
          "Limited to inspection and planning use cases",
          "Cannot alter or update metadata properties"
        ],
        bestFor: [
          "Table introspection and debugging",
          "Query performance analysis and optimization",
          "Data quality assessment and monitoring",
          "Understanding table evolution and changes"
        ]
      },
      technicalSpecs: [
        {
          category: "Metadata Functions",
          items: [
            { label: "iceberg_snapshots()", value: "Current first + summary", status: "available" },
            { label: "iceberg_metadata()", value: "File stats for planner", status: "available" },
            { label: "Summary JSON", value: "Quick diffing support", status: "available" },
            { label: "Cost Statistics", value: "For optimization", status: "available" }
          ]
        },
        {
          category: "Planning Integration",
          items: [
            { label: "File Size Stats", value: "Query planner input", status: "available" },
            { label: "Row Count Estimates", value: "Cost-based decisions", status: "available" },
            { label: "Partition Information", value: "Pruning optimization", status: "available" },
            { label: "Schema Metadata", value: "Type information", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Iceberg Extension Overview", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/overview.html", type: "docs" }
      ]
    }
  },
  {
    title: "Security Integration",
    chip: "Basic Support",
    description: "Uses DuckDB's standard S3/Azure credentials via httpfs extension; REST-catalog tokens per-session; no built-in RBAC/row-masking",
    icon: <ShieldCheckIcon className="w-6 h-6" />,
    color: "orange",
    score: 65,
    details: {
      title: "Foundation Security Features",
      description: "DuckDB provides essential security integration through standard cloud credentials and REST catalog authentication, suitable for basic access control needs.",
      overviewContent: {
        strengths: [
          "Standard cloud provider credential support",
          "REST catalog authentication with tokens",
          "Session-based security configuration",
          "Integration with object-store IAM policies",
          "CREATE SECRET workflow for credentials"
        ],
        limitations: [
          "No built-in row-level security or masking",
          "No advanced RBAC features within DuckDB",
          "Relies on object-store and catalog-level permissions",
          "Limited fine-grained access control capabilities"
        ],
        bestFor: [
          "Individual analyst workstations and development",
          "Simple access control through cloud IAM",
          "REST catalog deployments with token auth",
          "Basic data exploration with credential isolation"
        ]
      },
      technicalSpecs: [
        {
          category: "Authentication Methods",
          items: [
            { label: "S3 Credentials", value: "Via httpfs extension", status: "available" },
            { label: "Azure Credentials", value: "Standard methods", status: "available" },
            { label: "REST Catalog Tokens", value: "Per-session supply", status: "available" },
            { label: "CREATE SECRET", value: "Credential workflow", status: "available" }
          ]
        },
        {
          category: "Access Control",
          items: [
            { label: "Object Store IAM", value: "Delegated to cloud", status: "available" },
            { label: "Catalog ACLs", value: "REST catalog dependent", status: "available" },
            { label: "Row-level Security", value: "Not supported", status: "unavailable" },
            { label: "Column Masking", value: "Not supported", status: "unavailable" }
          ]
        }
      ],
      externalLinks: [
        { label: "S3 Iceberg Import", url: "https://duckdb.org/docs/stable/guides/network_cloud_storage/s3_iceberg_import.html", type: "docs" },
        { label: "Iceberg REST Catalogs Authentication", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/iceberg_rest_catalogs.html", type: "docs" }
      ]
    }
  },
  {
    title: "Current Limitations",
    chip: "Known Issues",
    description: "Read-only engine with no write support; tables with deletes not supported; Format V3 capabilities absent; single-node execution constraints",
    icon: <ExclamationTriangleIcon className="w-6 h-6" />,
    color: "red",
    score: 40,
    details: {
      title: "Understanding DuckDB Constraints",
      description: "While DuckDB excels at read-only analytics, several key limitations should be considered for comprehensive Iceberg workflows.",
      overviewContent: {
        strengths: [
          "Clear limitation documentation and transparency",
          "Focused scope enables optimization within constraints",
          "Roadmap visibility for upcoming write support",
          "Strong foundation for future capability expansion"
        ],
        limitations: [
          "No write operations (INSERT/CREATE TABLE AS ICEBERG)",
          "Reading tables with delete files not supported",
          "Format V3 features completely absent",
          "Single-node execution limits scale",
          "Partition pruning not fully cost-based for complex predicates"
        ],
        bestFor: [
          "Understanding current capability boundaries",
          "Planning workflows within read-only constraints",
          "Evaluating suitability for specific use cases",
          "Setting appropriate expectations for analytics workloads"
        ]
      },
      technicalSpecs: [
        {
          category: "Write Limitations",
          items: [
            { label: "INSERT Operations", value: "Not supported", status: "unavailable" },
            { label: "UPDATE Operations", value: "Not supported", status: "unavailable" },
            { label: "DELETE Operations", value: "Not supported", status: "unavailable" },
            { label: "CREATE TABLE AS", value: "Not supported", status: "unavailable" }
          ]
        },
        {
          category: "Format Limitations",
          items: [
            { label: "Tables with Deletes", value: "Cannot read", status: "unavailable" },
            { label: "Format V3 Tables", value: "Not supported", status: "unavailable" },
            { label: "Avro/ORC Files", value: "Ignored", status: "unavailable" },
            { label: "Complex Predicates", value: "Pruning limited", status: "limited" }
          ]
        }
      ],
      externalLinks: [
        { label: "Troubleshooting - Current Limitations", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/troubleshooting.html", type: "docs" },
        { label: "DuckDB 1.3.0 Release Notes", url: "https://duckdb.org/2025/05/21/announcing-duckdb-130.html", type: "blog" }
      ]
    }
  }
];

export const duckdbTableData = {
  title: "DuckDB Iceberg Feature Matrix",
  description: "Comprehensive breakdown of Iceberg capabilities in DuckDB v1.3+",
  variant: "default",
  columns: [
    {
      key: "dimension",
      header: "Dimension",
      tooltip: "Iceberg feature category or capability area",
      width: "w-64"
    },
    {
      key: "support",
      header: "Support Level",
      tooltip: "Level of support in DuckDB",
      align: "center",
      width: "w-32"
    },
    {
      key: "details",
      header: "Implementation Details",
      tooltip: "Specific capabilities and limitations"
    },
    {
      key: "version",
      header: "Min Version",
      tooltip: "Minimum DuckDB version required",
      align: "center",
      width: "w-24"
    }
  ],
  rows: [
    {
      dimension: {
        value: <span className="font-medium">Catalog Types</span>
      },
      support: {
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">Partial</span>,
        badge: { text: "Hadoop + REST", variant: "warning" },
        tooltip: "File-system and REST catalogs only"
      },
      details: {
        value: "Hadoop (file-system), REST catalog with OAuth tokens; no native Hive/Glue support",
        tooltip: "Can proxy Hive/Glue through REST but no direct catalog integration"
      },
      version: { value: "1.3+" }
    },
    {
      dimension: {
        value: <span className="font-medium">Read Operations</span>
      },
      support: {
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Full</span>,
        badge: { text: "Analytics Optimized", variant: "success" }
      },
      details: {
        value: "Complete SELECT support, predicate pushdown, manifest pruning, external file-cache",
        tooltip: "Optimized for analytical queries with cloud storage caching"
      },
      version: { value: "1.3+" }
    },
    {
      dimension: {
        value: <span className="font-medium">Write Operations</span>
      },
      support: {
        value: <span className="text-red-600 dark:text-red-400 font-semibold">None</span>,
        badge: { text: "Read-Only", variant: "error" }
      },
      details: {
        value: "No INSERT/UPDATE/DELETE/CREATE TABLE AS ICEBERG support",
        tooltip: "Write support is planned for future versions"
      },
      version: { value: "N/A" }
    },
    {
      dimension: {
        value: <span className="font-medium">Time Travel</span>
      },
      support: {
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Full</span>,
        badge: { text: "SQL Syntax", variant: "success" }
      },
      details: {
        value: "New AT (VERSION/TIMESTAMP) syntax plus legacy function-style options",
        tooltip: "Convenient SQL syntax for point-in-time queries"
      },
      version: { value: "1.3+" }
    },
    {
      dimension: {
        value: <span className="font-medium">Delete File Support</span>
      },
      support: {
        value: <span className="text-red-600 dark:text-red-400 font-semibold">None</span>,
        badge: { text: "CoW Only", variant: "error" }
      },
      details: {
        value: "Reading tables with deletes not yet supported; Copy-on-Write tables only",
        tooltip: "Merge-on-Read tables with delete files cannot be read"
      },
      version: { value: "N/A" }
    },
    {
      dimension: {
        value: <span className="font-medium">Format V3 Support</span>
      },
      support: {
        value: <span className="text-red-600 dark:text-red-400 font-semibold">None</span>,
        badge: { text: "V1/V2 Only", variant: "error" }
      },
      details: {
        value: "DuckDB 1.3 reads v1 & v2 tables only; V3 evaluation post-GA",
        tooltip: "No deletion vectors, row lineage, or new data types"
      },
      version: { value: "N/A" }
    },
    {
      dimension: {
        value: <span className="font-medium">Data File Formats</span>
      },
      support: {
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">Limited</span>,
        badge: { text: "Parquet Only", variant: "warning" }
      },
      details: {
        value: "Parquet files only; Avro/ORC data files are ignored",
        tooltip: "Mixed-format tables can only be partially read"
      },
      version: { value: "1.3+" }
    },
    {
      dimension: {
        value: <span className="font-medium">Streaming Support</span>
      },
      support: {
        value: <span className="text-red-600 dark:text-red-400 font-semibold">None</span>,
        badge: { text: "Batch Only", variant: "error" }
      },
      details: {
        value: "Batch-only analytics; no streaming ingestion or CDC capabilities",
        tooltip: "No real-time processing or change data capture features"
      },
      version: { value: "N/A" }
    },
    {
      dimension: {
        value: <span className="font-medium">Metadata Operations</span>
      },
      support: {
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Full</span>,
        badge: { text: "Helper Functions", variant: "success" }
      },
      details: {
        value: "iceberg_snapshots(), iceberg_metadata() with summary JSON and planner stats",
        tooltip: "Rich metadata introspection for debugging and optimization"
      },
      version: { value: "1.3+" }
    },
    {
      dimension: {
        value: <span className="font-medium">Cloud Storage Optimization</span>
      },
      support: {
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Full</span>,
        badge: { text: "File Cache", variant: "success" }
      },
      details: {
        value: "External file-cache via s3_cache_size reduces cold-scan latency by ~50%",
        tooltip: "Intelligent caching for S3/GCS objects with configurable size"
      },
      version: { value: "1.3+" }
    },
    {
      dimension: {
        value: <span className="font-medium">Security Integration</span>
      },
      support: {
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">Basic</span>,
        badge: { text: "Credential Delegation", variant: "warning" }
      },
      details: {
        value: "S3/Azure creds via httpfs, REST tokens; no built-in RBAC/row-masking",
        tooltip: "Relies on object-store IAM and catalog-level permissions"
      },
      version: { value: "1.3+" }
    },
    {
      dimension: {
        value: <span className="font-medium">Scale Limitations</span>
      },
      support: {
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">Single-Node</span>,
        badge: { text: "Local Resources", variant: "warning" }
      },
      details: {
        value: "Single-node execution; large lake queries constrained by local resources",
        tooltip: "Not designed for distributed processing of very large datasets"
      },
      version: { value: "1.3+" }
    }
  ]
};

export const duckdbUseCases = [
  {
    title: "Interactive Data Exploration",
    description: "Fast, ad-hoc analytics on Iceberg tables for data scientists and analysts",
    scenarios: [
      "Laptop-based data science with cloud data lakes",
      "Quick data quality assessment and profiling",
      "Prototyping data transformations and analysis",
      "Educational and learning environments"
    ]
  },
  {
    title: "Development & Testing",
    description: "Lightweight engine for developing and testing data pipelines",
    scenarios: [
      "Local development against production Iceberg tables",
      "Testing query logic before deploying to production",
      "Debugging data pipeline outputs and transformations",
      "Schema validation and compatibility testing"
    ]
  },
  {
    title: "Analytical Reporting",
    description: "Read-only reporting and dashboard data preparation",
    scenarios: [
      "Business intelligence report generation",
      "Data extraction for external systems and tools",
      "Historical trend analysis with time travel",
      "Cross-functional data sharing and exploration"
    ]
  },
  {
    title: "Data Lake Auditing",
    description: "Compliance and audit scenarios leveraging time travel capabilities",
    scenarios: [
      "Point-in-time data auditing and compliance",
      "Data lineage investigation and debugging",
      "Historical data comparison and validation",
      "Regulatory reporting with specific timestamps"
    ]
  }
];

<QueryEngineLayout
  title="DuckDB v1.3+"
  description="A light-weight, read-only analytics engine for Iceberg with SQL time travel, external file caching, and REST catalog support"
  features={duckdbFeatures}
  tableData={duckdbTableData}
  useCases={duckdbUseCases}
  officialDocs="https://duckdb.org/docs/"
  gettingStarted="https://duckdb.org/docs/stable/core_extensions/iceberg/overview.html"
  additionalResources={[
    { label: "Iceberg Extension Configuration", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/iceberg_rest_catalogs.html" },
    { label: "S3 Integration Guide", url: "https://duckdb.org/docs/stable/guides/network_cloud_storage/s3_iceberg_import.html" },
    { label: "DuckDB 1.3.0 Release", url: "https://duckdb.org/2025/05/21/announcing-duckdb-130.html" },
    { label: "Troubleshooting Guide", url: "https://duckdb.org/docs/stable/core_extensions/iceberg/troubleshooting.html" }
  ]}
/>