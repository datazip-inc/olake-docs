---
title: "Databricks Runtime 14.3 LTS+ & Apache Iceberg: UniForm Multi-Format Lakehouse | OLake"
description: "Explore OLake insights on Databricks Runtime 14.3 LTS+ enabling read-only Iceberg views of Delta tables via Unity Catalog REST, with time travel and enterprise governance."
sidebar_label: Databricks Runtime 14.3 LTS+
hide_table_of_contents: true
---

import { QueryEngineLayout } from '@site/src/components/Iceberg/QueryEngineLayout';
import { 
  CloudIcon,
  ShieldCheckIcon,
  ClockIcon,
  CubeIcon,
  ExclamationTriangleIcon,
  BoltIcon,
//   BoltIcon,
  ArrowPathIcon
} from '@heroicons/react/24/outline';

export const databricksFeatures = [
  {
    title: "Unity Catalog REST Integration",
    chip: "REST Endpoint",
    description: "Unity Catalog exposes Iceberg REST catalog at /api/2.1/unity-catalog/iceberg, enabling external engines to read UniForm tables with standard Iceberg clients",
    icon: <CloudIcon className="w-6 h-6" />,
    color: "blue",
    score: 85,
    details: {
      title: "Seamless External Engine Integration",
      description: "Databricks provides a standardized REST catalog endpoint that allows any Iceberg-compatible engine to discover and read Delta tables with UniForm enabled.",
      overviewContent: {
        strengths: [
          "Standard Iceberg REST catalog API compliance",
          "Automatic table discovery for external engines",
          "Credential vending for secure cloud storage access",
          "Support for all major Iceberg client libraries",
          "Unity Catalog metadata integration and governance"
        ],
        limitations: [
          "Read-only access for external Iceberg clients",
          "Limited to tables with IcebergCompatV2 enabled",
          "No native Hive Metastore or AWS Glue integration",
          "REST catalog limited to Unity Catalog managed tables"
        ],
        bestFor: [
          "Multi-engine lakehouse architectures",
          "External analytics tools requiring Iceberg access",
          "Data sharing across different compute engines",
          "Standardized metadata access for governance"
        ]
      },
      technicalSpecs: [
        {
          category: "REST Catalog Features",
          items: [
            { label: "API Endpoint", value: "/api/2.1/unity-catalog/iceberg", status: "available" },
            { label: "Authentication", value: "Personal Access Tokens", status: "available" },
            { label: "Credential Vending", value: "Scoped cloud storage", status: "available" },
            { label: "Table Discovery", value: "Automatic via REST", status: "available" }
          ]
        },
        {
          category: "External Engine Support",
          items: [
            { label: "Apache Spark", value: "Full compatibility", status: "available" },
            { label: "Trino/Presto", value: "Read support", status: "available" },
            { label: "Apache Flink", value: "Read support", status: "available" },
            { label: "DuckDB", value: "Read support", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Unity Catalog Iceberg Endpoint", url: "https://docs.databricks.com/aws/en/external-access/iceberg.html", type: "docs" },
        { label: "Access Databricks Tables from Iceberg Clients", url: "https://docs.databricks.com/aws/en/external-access/iceberg.html", type: "docs" }
      ]
    }
  },
  {
    title: "UniForm Multi-Format Technology",
    chip: "Innovative",
    description: "[UniForm](/iceberg/query-engine/snowflake) enables the same table to be accessible as both Delta and Iceberg simultaneously, generating Iceberg metadata on every Delta commit",
    icon: <ArrowPathIcon className="w-6 h-6" />,
    color: "purple",
    score: 95,
    details: {
      title: "Revolutionary Multi-Format Lakehouse",
      description: "UniForm technology represents a breakthrough in lakehouse architecture, allowing a single table to serve multiple engines with their native formats.",
      overviewContent: {
        strengths: [
          "Single source of truth with dual format access",
          "Automatic Iceberg metadata generation on Delta commits",
          "Zero data duplication between formats",
          "Seamless Delta feature integration (Liquid Clustering, etc.)",
          "Asynchronous metadata sync for performance"
        ],
        limitations: [
          "Requires IcebergCompatV2 feature flag enabled",
          "Tables with deletion vectors need purging first",
          "Streaming writes not compatible with UniForm",
          "Materialized views cannot enable Iceberg reads"
        ],
        bestFor: [
          "Organizations wanting to standardize on Delta while supporting Iceberg clients",
          "Multi-vendor tool environments requiring format flexibility",
          "Migration scenarios from legacy systems to modern lakehouse",
          "Data sharing across different technology stacks"
        ]
      },
      technicalSpecs: [
        {
          category: "UniForm Configuration",
          items: [
            { label: "Enable Property", value: "delta.universalFormat.enabledFormats=iceberg", status: "available" },
            { label: "Legacy Property", value: "delta.enableIcebergCompatV2=true", status: "available" },
            { label: "Metadata Sync", value: "Asynchronous on Delta commits", status: "available" },
            { label: "Manual Sync", value: "MSCK REPAIR TABLE â€¦ SYNC METADATA", status: "available" }
          ]
        },
        {
          category: "Format Features",
          items: [
            { label: "Iceberg Spec Version", value: "v2", status: "available" },
            { label: "Data Format", value: "Parquet with Zstandard", status: "available" },
            { label: "Delta Lineage", value: "converted_delta_version properties", status: "available" },
            { label: "Time Travel Mapping", value: "Delta to Iceberg timestamps", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Read Delta Tables with Iceberg Clients", url: "https://docs.databricks.com/aws/en/delta/uniform.html", type: "docs" },
        { label: "Full Apache Iceberg Support Announcement", url: "https://www.databricks.com/blog/announcing-full-apache-iceberg-support-databricks", type: "blog" }
      ]
    }
  },
  {
    title: "Read-Only Iceberg Access",
    chip: "External Engines",
    description: "External Iceberg engines get full SELECT and time-travel capabilities while Delta users retain complete DML operations within Databricks",
    icon: <BoltIcon className="w-6 h-6" />,
    color: "green",
    score: 80,
    details: {
      title: "Strategic Read-Only Architecture",
      description: "Databricks implements a clear separation where Delta remains the authoritative format for writes while Iceberg provides standardized read access for external engines.",
      overviewContent: {
        strengths: [
          "Full SELECT support for external Iceberg engines",
          "Standard Iceberg time travel and snapshot queries",
          "Complete Delta DML capabilities within Databricks",
          "Consistent read views across all external engines",
          "No conflicts between Delta writes and Iceberg reads"
        ],
        limitations: [
          "Iceberg clients cannot perform INSERT/UPDATE/DELETE operations",
          "No Iceberg-native write operations through REST catalog",
          "External engines depend on Delta commit frequency for freshness",
          "Cannot use Iceberg-specific write optimizations externally"
        ],
        bestFor: [
          "Analytics workloads requiring external engine access",
          "Data sharing scenarios with read-only requirements",
          "Multi-tenant environments with controlled write access",
          "Compliance scenarios requiring immutable external views"
        ]
      },
      technicalSpecs: [
        {
          category: "Read Capabilities",
          items: [
            { label: "SELECT Queries", value: "Full SQL support", status: "available" },
            { label: "Time Travel", value: "Snapshot ID and timestamp", status: "available" },
            { label: "Predicate Pushdown", value: "Engine-dependent", status: "available" },
            { label: "Metadata Queries", value: "Standard Iceberg operations", status: "available" }
          ]
        },
        {
          category: "Write Limitations",
          items: [
            { label: "INSERT Operations", value: "Delta only", status: "limited" },
            { label: "UPDATE Operations", value: "Delta only", status: "limited" },
            { label: "DELETE Operations", value: "Delta only", status: "limited" },
            { label: "MERGE Operations", value: "Delta only", status: "limited" }
          ]
        }
      ],
      externalLinks: [
        { label: "Read Delta Tables - Limitations", url: "https://docs.databricks.com/aws/en/delta/uniform.html", type: "docs" }
      ]
    }
  },
  {
    title: "Copy-on-Write Semantics",
    chip: "CoW Only",
    description: "Delta commits use Copy-on-Write semantics with no Iceberg delete files; external readers always see fully merged, materialized snapshots",
    icon: <CubeIcon className="w-6 h-6" />,
    color: "orange",
    score: 75,
    details: {
      title: "Simplified Storage Strategy",
      description: "Databricks UniForm implements a Copy-on-Write approach that ensures external Iceberg readers always see clean, fully materialized data without merge complexity.",
      overviewContent: {
        strengths: [
          "Consistent read performance without merge overhead",
          "Fully materialized snapshots for external engines",
          "No delete file complexity for Iceberg clients",
          "Simplified troubleshooting and debugging",
          "Optimized for analytical read workloads"
        ],
        limitations: [
          "No Merge-on-Read optimizations for frequent updates",
          "Higher storage overhead for update-heavy workloads",
          "Cannot leverage Iceberg delete file efficiency",
          "Limited to CoW performance characteristics"
        ],
        bestFor: [
          "Read-heavy analytical workloads",
          "Scenarios prioritizing read performance over write efficiency",
          "External engines requiring consistent snapshot views",
          "Use cases where merge complexity should be avoided"
        ]
      },
      technicalSpecs: [
        {
          category: "Storage Strategy",
          items: [
            { label: "Write Strategy", value: "Copy-on-Write only", status: "available" },
            { label: "Delete Files", value: "Not generated", status: "unavailable" },
            { label: "Snapshot Views", value: "Fully materialized", status: "available" },
            { label: "Read Performance", value: "Consistent", status: "available" }
          ]
        },
        {
          category: "Delta Integration",
          items: [
            { label: "Delta Features", value: "Full compatibility", status: "available" },
            { label: "Liquid Clustering", value: "Supported", status: "available" },
            { label: "Predictive Optimization", value: "Available", status: "available" },
            { label: "Deletion Vectors", value: "Must be purged", status: "limited" }
          ]
        }
      ],
      externalLinks: [
        { label: "Unity Catalog Iceberg Endpoint - Notes", url: "https://docs.databricks.com/aws/en/external-access/iceberg.html", type: "docs" }
      ]
    }
  },
  {
    title: "Metadata Generation & Sync",
    chip: "Asynchronous",
    description: "Iceberg metadata generated asynchronously on every Delta commit with manual sync option via MSCK REPAIR TABLE â€¦ SYNC METADATA",
    icon: <BoltIcon className="w-6 h-6" />,
    color: "blue",
    score: 80,
    details: {
      title: "Intelligent Metadata Management",
      description: "Databricks automates Iceberg metadata generation while providing controls for immediate synchronization when needed for time-sensitive workflows.",
      overviewContent: {
        strengths: [
          "Automatic metadata generation on every Delta commit",
          "Non-blocking asynchronous process for performance",
          "Manual sync capability for immediate consistency",
          "Delta version mapping for audit trails",
          "Timestamp correlation between formats"
        ],
        limitations: [
          "Potential lag between Delta commits and Iceberg visibility",
          "Manual intervention required for immediate consistency",
          "Async process may delay external engine data availability",
          "No real-time streaming metadata updates"
        ],
        bestFor: [
          "Batch processing workflows with acceptable latency",
          "Scenarios where eventual consistency is sufficient",
          "Use cases requiring audit trails and version mapping",
          "Environments with mixed batch and real-time requirements"
        ]
      },
      technicalSpecs: [
        {
          category: "Metadata Generation",
          items: [
            { label: "Sync Mode", value: "Asynchronous by default", status: "available" },
            { label: "Manual Sync", value: "MSCK REPAIR TABLE â€¦ SYNC METADATA", status: "available" },
            { label: "Delta Mapping", value: "converted_delta_version properties", status: "available" },
            { label: "Timestamp Mapping", value: "converted_delta_timestamp", status: "available" }
          ]
        },
        {
          category: "Consistency Features",
          items: [
            { label: "Eventual Consistency", value: "Default behavior", status: "available" },
            { label: "Immediate Consistency", value: "Via manual sync", status: "available" },
            { label: "Version Tracking", value: "Delta to Iceberg mapping", status: "available" },
            { label: "Audit Trail", value: "Complete lineage", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Enable Iceberg Metadata Generation", url: "https://docs.databricks.com/aws/en/delta/uniform.html", type: "docs" }
      ]
    }
  },
  {
    title: "Time Travel & Snapshot Queries",
    chip: "Full Support",
    description: "External engines can [time-travel](/blog/apache-polaris-lakehouse) using standard Iceberg syntax with snapshot-ID or timestamp, enhanced with Delta version mapping properties",
    icon: <ClockIcon className="w-6 h-6" />,
    color: "green",
    score: 90,
    details: {
      title: "Comprehensive Historical Query Support",
      description: "Databricks provides full Iceberg time travel capabilities while maintaining Delta version correlation for comprehensive historical analysis.",
      overviewContent: {
        strengths: [
          "Standard Iceberg time travel syntax support",
          "Snapshot-ID and timestamp-based queries",
          "Delta version correlation for cross-format analysis",
          "Comprehensive audit trail capabilities",
          "Seamless integration with external tools"
        ],
        limitations: [
          "Time travel limited to available snapshots",
          "Historical queries depend on snapshot retention policies",
          "Cannot time travel beyond earliest Delta conversion",
          "Performance varies with historical data volume"
        ],
        bestFor: [
          "Data auditing and compliance scenarios",
          "Historical trend analysis across formats",
          "Debugging and root cause analysis",
          "Regulatory reporting with specific timestamps"
        ]
      },
      technicalSpecs: [
        {
          category: "Time Travel Features",
          items: [
            { label: "Snapshot ID Queries", value: "Standard Iceberg syntax", status: "available" },
            { label: "Timestamp Queries", value: "as-of-timestamp support", status: "available" },
            { label: "Delta Version Mapping", value: "converted_delta_version", status: "available" },
            { label: "Cross-format Correlation", value: "Delta to Iceberg timestamps", status: "available" }
          ]
        },
        {
          category: "Historical Analysis",
          items: [
            { label: "Audit Capabilities", value: "Complete version history", status: "available" },
            { label: "Compliance Queries", value: "Point-in-time accuracy", status: "available" },
            { label: "Data Lineage", value: "Format transition tracking", status: "available" },
            { label: "External Tool Integration", value: "Standard APIs", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Iceberg REST API Specification", url: "https://github.com/apache/iceberg/blob/master/api/src/main/java/org/apache/iceberg/rest/RestCatalog.java", type: "docs" }
      ]
    }
  },
  {
    title: "Enterprise Security & Governance",
    chip: "Unity Catalog",
    description: "Unity Catalog RBAC governs access with credential vending providing temporary, scoped cloud-storage credentials to external Iceberg clients",
    icon: <ShieldCheckIcon className="w-6 h-6" />,
    color: "green",
    score: 95,
    details: {
      title: "Enterprise-Grade Access Control",
      description: "Databricks integrates comprehensive security through Unity Catalog with advanced credential vending for secure external access without credential sharing.",
      overviewContent: {
        strengths: [
          "Centralized RBAC through Unity Catalog",
          "Automatic credential vending for external clients",
          "Scoped, temporary cloud storage credentials",
          "Fine-grained table and column-level permissions",
          "Audit logging for all external access"
        ],
        limitations: [
          "Security model tied to Unity Catalog implementation",
          "External clients must support REST catalog authentication",
          "Credential vending limited to supported cloud providers",
          "Fine-grained permissions depend on Unity Catalog features"
        ],
        bestFor: [
          "Enterprise environments requiring strict access control",
          "Multi-tenant deployments with isolation requirements",
          "Compliance scenarios with audit trail needs",
          "Organizations with existing Unity Catalog governance"
        ]
      },
      technicalSpecs: [
        {
          category: "Access Control",
          items: [
            { label: "RBAC System", value: "Unity Catalog integration", status: "available" },
            { label: "Credential Vending", value: "Temporary, scoped tokens", status: "available" },
            { label: "Table Permissions", value: "Fine-grained control", status: "available" },
            { label: "Column Security", value: "Unity Catalog features", status: "available" }
          ]
        },
        {
          category: "Security Features",
          items: [
            { label: "Audit Logging", value: "All external access", status: "available" },
            { label: "Token Management", value: "Automatic renewal", status: "available" },
            { label: "Cloud Integration", value: "AWS, Azure, GCP", status: "available" },
            { label: "Network Security", value: "VPC/VNet integration", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Access Databricks Tables from Iceberg Clients", url: "https://docs.databricks.com/aws/en/external-access/iceberg.html", type: "docs" }
      ]
    }
  },
  {
    title: "Current Limitations & Requirements",
    chip: "Important Constraints",
    description: "Tables with deletion vectors, streaming writes, or materialized views require purging/upgrade before Iceberg compatibility; Runtime 14.3 LTS+ required",
    icon: <ExclamationTriangleIcon className="w-6 h-6" />,
    color: "red",
    score: 60,
    details: {
      title: "Understanding Compatibility Requirements",
      description: "Databricks UniForm has specific requirements and limitations that must be considered when planning Iceberg integration strategies.",
      overviewContent: {
        strengths: [
          "Clear documentation of limitations and workarounds",
          "Automated upgrade tools for compatibility",
          "Specific runtime version requirements documented",
          "Roadmap visibility for future capability expansion"
        ],
        limitations: [
          "Tables with deletion vectors require REORG â€¦ PURGE DELETION_VECTORS",
          "Streaming writes incompatible with UniForm",
          "Materialized views cannot enable Iceberg reads",
          "REST catalog is read-only for external engines",
          "Iceberg spec v3 not yet supported"
        ],
        bestFor: [
          "Understanding migration planning requirements",
          "Evaluating compatibility with existing workloads",
          "Setting appropriate expectations for capabilities",
          "Planning workarounds for current limitations"
        ]
      },
      technicalSpecs: [
        {
          category: "Version Requirements",
          items: [
            { label: "Databricks Runtime", value: "14.3 LTS or newer", status: "available" },
            { label: "REST API Version", value: "2.1", status: "available" },
            { label: "Iceberg Spec Support", value: "v2 only", status: "limited" },
            { label: "Managed Iceberg", value: "Runtime 16.4 LTS+", status: "preview" }
          ]
        },
        {
          category: "Table Compatibility",
          items: [
            { label: "Deletion Vectors", value: "Must be purged", status: "limited" },
            { label: "Streaming Writes", value: "Not compatible", status: "unavailable" },
            { label: "Materialized Views", value: "Cannot enable", status: "unavailable" },
            { label: "Standard Tables", value: "Full support", status: "available" }
          ]
        }
      ],
      externalLinks: [
        { label: "Read Delta Tables - Limitations", url: "https://docs.databricks.com/aws/en/delta/uniform.html", type: "docs" },
        { label: "Full Apache Iceberg Support - V2 Preview", url: "https://www.databricks.com/blog/announcing-full-apache-iceberg-support-databricks", type: "blog" }
      ]
    }
  }
];

export const databricksTableData = {
  title: "Databricks Iceberg Feature Matrix",
  description: "Comprehensive breakdown of Iceberg capabilities in Databricks Runtime 14.3 LTS+. The matrix shows feature support levels, implementation details, and minimum version requirements for your lakehouse architecture.",
  variant: "default",
  columns: [
    {
      key: "dimension",
      header: "Dimension",
      tooltip: "Iceberg feature category or capability area",
      width: "w-64"
    },
    {
      key: "support",
      header: "Support Level",
      tooltip: "Level of support in Databricks",
      align: "center",
      width: "w-32"
    },
    {
      key: "details",
      header: "Implementation Details",
      tooltip: "Specific capabilities and limitations"
    },
    {
      key: "version",
      header: "Min Version",
      tooltip: "Minimum Databricks Runtime required",
      align: "center",
      width: "w-24"
    }
  ],
  rows: [
    {
      dimension: { 
        value: <span className="font-medium">Catalog Integration</span> 
      },
      support: { 
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">REST Only</span>,
        badge: { text: "Unity Catalog", variant: "warning" },
        tooltip: "REST catalog endpoint at /api/2.1/unity-catalog/iceberg"
      },
      details: { 
        value: "Unity Catalog REST endpoint for external engines; UniForm tables generate Iceberg metadata on Delta commits",
        tooltip: "No native Hive/Glue support, REST catalog only"
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Read Operations</span> 
      },
      support: { 
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Full</span>,
        badge: { text: "External Engines", variant: "success" }
      },
      details: { 
        value: "Complete SELECT support via REST catalog or direct metadata paths for all Iceberg-compatible engines",
        tooltip: "Full read access for Spark, Trino, Flink, DuckDB, etc."
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Write Operations</span> 
      },
      support: { 
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">Partial</span>,
        badge: { text: "Delta Internal", variant: "warning" }
      },
      details: { 
        value: "Managed Iceberg Tables support external writes; UniForm Delta tables read-only for Iceberg clients",
        tooltip: "Full DML inside Databricks, external writes only for Managed Iceberg"
      },
      version: { value: "16.4 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">UniForm Technology</span> 
      },
      support: { 
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Full</span>,
        badge: { text: "Multi-Format", variant: "success" }
      },
      details: { 
        value: "Same table accessible as Delta and Iceberg simultaneously with automatic metadata generation",
        tooltip: "Revolutionary multi-format lakehouse capability"
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Time Travel</span> 
      },
      support: { 
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Full</span>,
        badge: { text: "Standard Syntax", variant: "success" }
      },
      details: { 
        value: "Standard Iceberg time travel with snapshot-ID/timestamp plus Delta version mapping properties",
        tooltip: "Complete historical query support with format correlation"
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Storage Strategy</span> 
      },
      support: { 
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">CoW Only</span>,
        badge: { text: "Copy-on-Write", variant: "warning" }
      },
      details: { 
        value: "Copy-on-Write semantics with no Iceberg delete files; fully materialized snapshots",
        tooltip: "No Merge-on-Read, all updates create new data files"
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Metadata Sync</span> 
      },
      support: { 
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Async</span>,
        badge: { text: "Auto + Manual", variant: "success" }
      },
      details: { 
        value: "Asynchronous generation on Delta commits with MSCK REPAIR TABLE â€¦ SYNC METADATA for immediate sync",
        tooltip: "Automatic with manual override for time-sensitive scenarios"
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Security & Governance</span> 
      },
      support: { 
        value: <span className="text-green-600 dark:text-green-400 font-semibold">Full</span>,
        badge: { text: "Unity Catalog", variant: "success" }
      },
      details: { 
        value: "Unity Catalog RBAC with credential vending for scoped, temporary cloud storage access",
        tooltip: "Enterprise-grade security with automatic credential management"
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Streaming Support</span> 
      },
      support: { 
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">Internal</span>,
        badge: { text: "Delta Only", variant: "warning" }
      },
      details: { 
        value: "Structured Streaming and Change Data Feed inside Databricks; no Iceberg streaming endpoints",
        tooltip: "Streaming limited to Delta format, not exposed via Iceberg REST"
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Format V3 Support</span> 
      },
      support: { 
        value: <span className="text-red-600 dark:text-red-400 font-semibold">None</span>,
        badge: { text: "V2 Only", variant: "error" }
      },
      details: { 
        value: "UniForm targets Iceberg spec v2 only; no public v3 roadmap announced",
        tooltip: "Limited to spec v2 features, no deletion vectors or row lineage"
      },
      version: { value: "N/A" }
    },
    {
      dimension: { 
        value: <span className="font-medium">Table Compatibility</span> 
      },
      support: { 
        value: <span className="text-yellow-600 dark:text-yellow-400 font-semibold">Limited</span>,
        badge: { text: "Upgrade Required", variant: "warning" }
      },
      details: { 
        value: "Tables with deletion vectors, streaming writes, or materialized views need REORG/upgrade",
        tooltip: "Specific requirements and limitations for table types"
      },
      version: { value: "14.3 LTS+" }
    },
    {
      dimension: { 
        value: <span className="font-medium">External Write Access</span> 
      },
      support: { 
        value: <span className="text-red-600 dark:text-red-400 font-semibold">Read-Only</span>,
        badge: { text: "REST Limitation", variant: "error" }
      },
      details: { 
        value: "REST catalog provides read-only access; no external Iceberg DML operations",
        tooltip: "External engines cannot perform INSERT/UPDATE/DELETE via REST"
      },
      version: { value: "N/A" }
    }
  ]
};

export const databricksUseCases = [
  {
    title: "Multi-Engine Lakehouse",
    description: "Enable external analytics tools and engines to access Delta tables via standard Iceberg APIs",
    scenarios: [
      "Practical example: A data science team at a Fortune 500 company maintains their core data in Databricks Delta tables for internal analytics. When external partners need access to this data, they enable UniForm to expose the tables via Iceberg REST catalog. External partners can now query the data using Apache Spark or Trino in their own infrastructure without requiring Databricks access or data duplication",
      "Business intelligence tools requiring Iceberg connectivity for reporting",
      "Data science platforms with Iceberg client libraries for ML workflows",
      "External Spark clusters needing read access to Delta tables for processing"
    ]
  },
  {
    title: "Data Sharing & Federation",
    description: "Share Delta table data across organizational boundaries with standardized Iceberg access",
    scenarios: [
      "Practical example: A healthcare consortium shares patient outcome data across 15 hospitals. Each hospital uses different analytics tools (some use Databricks, others use Trino or Presto). By enabling UniForm on Delta tables, the central data warehouse provides Iceberg-compatible access, allowing each hospital to query shared data using their preferred tools while maintaining strict Unity Catalog security controls",
      "Cross-team data sharing with different tool preferences and requirements",
      "Partner organizations requiring standard data access without vendor dependencies",
      "Data marketplace implementations with unified access patterns"
    ]
  },
  {
    title: "Migration & Modernization",
    description: "Gradually migrate from legacy systems while maintaining backward compatibility",
    scenarios: [
      "Practical example: A retail company is migrating from legacy Hive tables to Databricks Delta. During the 6-month transition period, they enable UniForm to allow their existing Tableau dashboards (which connect via Iceberg) to continue working while they gradually migrate reports to use native Delta connections. This phased approach eliminates 'big bang' migration risks",
      "Transitioning from Hive tables to Delta with external tool support",
      "Legacy analytics tools requiring Iceberg compatibility during migration",
      "Hybrid architectures during platform modernization initiatives"
    ]
  },
  {
    title: "Compliance & Governance",
    description: "Provide auditable, read-only access for compliance and regulatory scenarios",
    scenarios: [
      "Practical example: A financial institution must provide read-only access to their transaction data for external auditors during quarterly reviews. Using UniForm with Unity Catalog, they expose specific tables via Iceberg REST catalog with time-bound credentials, ensuring auditors can verify data independently without granting write access or exposing sensitive internal systems",
      "Regulatory reporting with external audit tools and compliance frameworks",
      "Compliance teams requiring independent data access with audit trails",
      "Data governance with Unity Catalog integration for fine-grained control"
    ]
  }
];

<QueryEngineLayout
  title="Databricks Runtime 14.3 LTS+"
  description="UniForm technology enables multi-format lakehouse with read-only Iceberg views of Delta tables via Unity Catalog REST endpoint"
  features={databricksFeatures}
  tableData={databricksTableData}
  useCases={databricksUseCases}
  officialDocs="https://docs.databricks.com/"
  gettingStarted="https://docs.databricks.com/aws/en/delta/uniform.html"
  additionalResources={[
    { label: "Unity Catalog Iceberg Endpoint", url: "https://docs.databricks.com/aws/en/external-access/iceberg.html" },
    { label: "UniForm Configuration Guide", url: "https://docs.databricks.com/aws/en/delta/uniform.html" },
    { label: "Full Iceberg Support Blog", url: "https://www.databricks.com/blog/announcing-full-apache-iceberg-support-databricks" },
    { label: "Credential Vending Documentation", url: "https://docs.databricks.com/aws/en/external-access/iceberg.html" }
  ]}
/>