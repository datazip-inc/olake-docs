import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# MongoDB Source Documentation

## A. Setup Prerequisites

Before beginning, ensure the following are installed and running:

- Docker and Docker Compose (latest version)
- MongoDB instance (local or remote) with credentials ready to act as source

### Required Components
- Olake Docker Image: `olakego/source-mongodb:latest`
- Iceberg REST Catalog service: `http://host.docker.internal:8181/catalog`
- MinIO/S3 bucket for storage: `http://host.docker.internal:9000`
- Spark SQL or Trino (with Iceberg Catalog configured) for querying.

### Additional Note: CDC Requirements for MongoDB
If you want Olake to continuously capture new changes (CDC mode), MongoDB must:
- Be started in replica set mode (`--replSet rs0`).
- Have oplog enabled (automatic in replica sets).
- Have a user with both:
  - `readWrite` role on your database, and
  - `read` role on the local database (to read oplog).

### Steps for CDC Setup

#### 1. Run MongoDB in Replica Set Mode
By default, MongoDB runs as a standalone server → this does not have an oplog. You need to start it with Replica Set Name.

If MongoDB is running inside Docker then execute:

```bash
docker run -d --name mongodb  -p 27017:27017  mongo:6.0 --replSet rs0
```

If MongoDB is running outside Docker then execute:

```bash
mongod --replSet rs0 --bind_ip_all
```

#### 2. Initialize Replica Set
Once MongoDB is running, you must initialise the replica set (just starting with `--replSet` is not enough).

Open a Mongo shell:

```bash
docker exec -it mongodb mongosh
```

Then run:

```bash
rs.initiate()
```

You should see something like:

```bash
{ "ok" : 1 }
```

✅ Now your MongoDB has a replica set and oplog enabled.

#### 3. Create a User
Olake needs a user that can:
- Read/write your application database (to ingest data).
- Read from the local database (where oplog is stored).

Create the user in the `admin` database:

```javascript
use admin
db.createUser({
  user: "olake_user",
  pwd: "your_password",
  roles: [
    { role: "readWrite", db: "your_db" },
    { role: "read", db: "local" }
  ]
})
```

#### 4. Verify oplog
Check that the oplog collection exists:

```javascript
use local
show collections
db.oplog.rs.findOne()
```

If you see an entry, ✅ oplog is working.

---

## B. Configuration

<Tabs>

  <TabItem value="ui" label="OLake UI" default>

### Create MongoDB Source Setup via Olake UI

Once the Olake UI setup is finished these steps can be followed:

1. Open Olake Web Console → [https://localhost:8000](https://localhost:8000)
2. Login with `Username: admin` / `Password: password`
3. Go to **Sources → + Create Source**.
4. Select **MongoDB** from the list.
5. Fill connection details.
6. Save changes.

The following image shows the Olake UI configuration screen. Use it as a reference to provide MongoDB connection details when creating the source:

![Olake UI MongoDB Source Setup](/img/connectors/mongodb/mongodb-ui-setup.png)

**Description of above parameters:**

| Field | Description | Example Value | Data Type |
|-------|-------------|---------------|-----------|
| `hosts` | List of MongoDB hosts. Use DNS SRV if `srv = true`. | `x.xxx.xxx.120:27017`, `x.xxx.xxx.120:27017`, `x.xxx.xxx.133:27017` (can be multiple) | STRING[] |
| `username`/`password` | Credentials for MongoDB authentication. | `"test"`/`"test"` | STRING |
| `authdb` | Authentication database (often `admin`). | `"admin"` | STRING |
| `replica_set` | Name of the replica set, if applicable. | `"rs0"` | STRING |
| `read_preference` | Which node to read from (e.g., `secondaryPreferred`). | `"secondaryPreferred"` | STRING |
| `srv` | If using DNS SRV connection strings, set to `true`. When `true`, there can only be 1 host in `hosts` field. | If `true`, the `hosts` key will have a value something like `["mongodatatest.pigiy.mongodb.net"]` | `true`, `false` | BOOL |
| `database` | The MongoDB database name to replicate. | `"database_name"` | STRING |
| `max_threads` | Maximum parallel threads for chunk-based snapshotting. | `5` | INT |
| `backoff_retry_count` | Retries attempt to establish sync again if it fails, increases exponentially (in minutes - 1, 2, 4, 8, 16... depending upon the `backoff_retry_count` value) | defaults to 3, takes default value if set to -1 | INT |
| `chunking_strategy` | The chunking strategy used for backfill. <br/>- `timestamp`: Splits data based on time fields.<br/>- `bucket_auto`: Uses MongoDB’s `$bucketAuto` for automatic bucketing.<br/>- `splitVector`: Uses the built-in `splitVector` command. <br/>If left empty, defaults to `splitVector`. <br/>Refer [here](../../../blog/2025-05-07-what-makes-olake-fast#mongodb) for more details. | `"timestamp"` / `"bucket_auto"` / `"splitVector"` | STRING |


  </TabItem>

  <TabItem value="cli" label="OLake CLI">

### MongoDB Source Setup via Olake CLI

#### A) Create config directory

Create a folder (directory) where we will store `source.json` so everything is organised.

You can create this directory in two ways:

**Option 1:** You can manually create a folder.

**Option 2:**

```bash
mkdir olake-mongodb
cd olake-mongodb
```

#### B) Create a file named `source.json` with MongoDB connection details

**Example:**

```json
{
  "hosts": ["host1:27017", "host2:27017", "host3:27017"],
  "username": "your_username",
  "password": "your_password",
  "authdb": "admin",
  "replica_set": "rs0",
  "read_preference": "secondaryPreferred",
  "srv": false,
  "database": "your_db",
  "max_threads": 5,
  "backoff_retry_count": 4,
  "chunking_strategy": ""
}
```

**Description of above parameters:**

| Field | Description | Example Value | Data Type |
|-------|-------------|---------------|-----------|
| `hosts` | List of MongoDB hosts. Use DNS SRV if `srv = true`. | `x.xxx.xxx.120:27017`, `x.xxx.xxx.120:27017`, `x.xxx.xxx.133:27017` (can be multiple) | STRING[] |
| `username`/`password` | Credentials for MongoDB authentication. | `"test"`/`"test"` | STRING |
| `authdb` | Authentication database (often `admin`). | `"admin"` | STRING |
| `replica_set` | Name of the replica set, if applicable. | `"rs0"` | STRING |
| `read_preference` | Which node to read from (e.g., `secondaryPreferred`). | `"secondaryPreferred"` | STRING |
| `srv` | If using DNS SRV connection strings, set to `true`. When `true`, there can only be 1 host in `hosts` field. | If `true`, the `hosts` key will have a value something like `["mongodatatest.pigiy.mongodb.net"]` | `true`, `false` | BOOL |
| `database` | The MongoDB database name to replicate. | `"database_name"` | STRING |
| `max_threads` | Maximum parallel threads for chunk-based snapshotting. | `5` | INT |
| `backoff_retry_count` | Retries attempt to establish sync again if it fails, increases exponentially (in minutes - 1, 2, 4, 8, 16... depending upon the `backoff_retry_count` value) | defaults to 3, takes default value if set to -1 | INT |
| `chunking_strategy` | The chunking strategy used for backfill. <br/>- `timestamp`: Splits data based on time fields.<br/>- `bucket_auto`: Uses MongoDB’s `$bucketAuto` for automatic bucketing.<br/>- `splitVector`: Uses the built-in `splitVector` command. <br/>If left empty, defaults to `splitVector`. <br/>Refer [here](../../../blog/2025-05-07-what-makes-olake-fast#mongodb) for more details. | `"timestamp"` / `"bucket_auto"` / `"splitVector"` | STRING |

#### C) Run Discover Command

The Discover command generates json content for `streams.json` file, which defines the schema of the collections to be synced.

<Tabs>

  <TabItem value="olake_docker" label="OLake Docker" default>

    <Tabs>

  <TabItem value="olake_docker_linux" label="Linux/macOS" default>

```bash
docker run --pull=always \
  -v "$HOME/PATH_TO_OLAKE_DIRECTORY:/mnt/config" \
  olakego/source-mongodb:latest \
  discover \
  --config /mnt/config/source.json
```

</TabItem>

<TabItem value="olake_docker_cmd" label="Windows (CMD)">


```cmd
docker run --pull=always ^
  -v "%USERPROFILE%\PATH_TO_OLAKE_DIRECTORY:/mnt/config" ^
  olakego/source-mongodb:latest ^
  discover ^
  --config /mnt/config/source.json
```

</TabItem>

<TabItem value="olake_docker_powershell" label="Powershell">


```powershell
docker run --pull=always `
  -v "$env:USERPROFILE\PATH_TO_OLAKE_DIRECTORY:/mnt/config" `
  olakego/source-mongodb:latest `
  discover `
  --config /mnt/config/source.json
```

</TabItem>

</Tabs>

</TabItem>

<TabItem value="locally_run_olake" label="Locally Run OLake">

<Tabs>

  <TabItem value="locally_run_olake_linux" label="Linux/macOS" default>

```bash
OLAKE_BASE_PATH="$HOME/PATH_TO_OLAKE_DIRECTORY/olake/drivers/mongodb/config" && \
./build.sh driver-mongodb discover \
  --config "$OLAKE_BASE_PATH/source.json"
```

</TabItem>

<TabItem value="locally_run_olake_cmd" label="Windows (CMD)">

```cmd
set "OLAKE_BASE_PATH=%USERPROFILE%\PATH_TO_OLAKE_DIRECTORY\olake\drivers\mongodb\config" && ^
./build.sh driver-mongodb discover ^
  --config "%OLAKE_BASE_PATH%\source.json"
```

</TabItem>

<TabItem value="locally_run_olake_powershell" label="Powershell">

```powershell
$OLAKE_BASE_PATH = "$env:USERPROFILE\PATH_TO_OLAKE_DIRECTORY\olake\drivers\mongodb\config"; `
./build.sh driver-mongodb discover `
  --config "$OLAKE_BASE_PATH\source.json"
```

</TabItem>

</Tabs>

</TabItem>

</Tabs>

The streams section is an array where each element is an object that defines a specific data stream. Each stream object includes a stream key that holds the configuration details. For example, one stream definition looks like this:

```json
{
  "stream": {
    "name": "stream_8",
    "namespace": "otter_db",
    "type_schema": {
      "properties": {
        "_id": {
          "type": ["string"]
        },
        "authors": {
          "type": ["array"]
        },
        "backreferences": {
          "type": ["array"]
        },
        "birth_date": {
          "type": ["string"]
        },
        ...
      }
    },
    "supported_sync_modes": ["full_refresh", "cdc"],
    "source_defined_primary_key": ["_id"],
    "available_cursor_fields": [],
    "sync_mode": "cdc"
  }
}
```

**The details about the streams element are mentioned below:**

| Field | Type | Example | Description |
|-------|------|---------|-------------|
| `name` | String | `stream_8` | Name of the stream (collection). |
| `namespace` | String | `otter_db` | Database name. |
| `type_schema` | Object | | Schema of fields | JSON schema of collection. |
| `supported_sync_modes` | Array | `["Full Refresh","Incremental", "CDC", "Strict CDC"]` | Supported replication methods. |
| `source_defined_primary_key` | Array | `["_id"]` | Specifies the field(s) that uniquely identify a record within the stream. This key is used to ensure data uniqueness and integrity. |
| `available_cursor_fields` | Array | [] | Lists fields that can be used to track the synchronization progress. Often empty if no cursors are required or defined. |
| `sync_mode` | String | `"Full Refresh"`/`"Incremental"`/`"CDC"`/`"Strict CDC"` | Indicates the active synchronization mode. |

Sample configuration of `streams.json` file is mentioned below:

```json
{
    "selected_streams": {
        "otter_db": [
            {
                "partition_regex": "{now(),2025,YYYY}-{now(),06,MM}-{now(),13,DD}/{string_change_language,,}",
                "stream_name": "stream_0",
                "normalization": false,
                "append_only": false,
                "chunk_column": "",         //column name to be specified
            },
            {
                "partition_regex": "{,1999,YYYY}-{,09,MM}-{,31,DD}/{latest_revision,,}",
                "stream_name": "stream_8",
                "normalization": false,
                "append_only": false,
                "chunk_column": "",         //column name to be specified

            }
        ]
    },
    "streams": [
        {
            "stream": {
                "name": "stream_8",
                "namespace": "otter_db",
                "type_schema": { ... },
                "supported_sync_modes": [
                    "full_refresh",
                    "cdc"
                ],
                "source_defined_primary_key": [
                    "_id"
                ],
                "available_cursor_fields": [],
                "sync_mode": "cdc"
            }
        },
    // ... other streams
  ]
}
```


#### D) Running the Sync

Once `source.json`, `streams.json`, and `destination.json` are ready, you can run the sync jobs.

ℹ️ **Note:** Instructions for creating the `destination.json` file are provided in the MongoDB Destination Document. Link to this document is provided [here](../../core/configs/writer.mdx)

The Sync command fetches data from MongoDB and ingests it into the specified destination (e.g., Iceberg on MinIO/S3).

##### 1. Full Data Sync (No State Tracking)

This will ingest the entire dataset each time (no CDC or checkpointing).

```bash
docker run --pull=always \
  -v "$HOME/PATH_TO_OLAKE_DIRECTORY:/mnt/config" \
  olakego/source-mongodb:latest \
  sync \
  --config /mnt/config/source.json \
  --catalog /mnt/config/streams.json \
  --destination /mnt/config/destination.json
```

##### 2. Incremental / CDC Sync (With State Tracking)

This mode enables change data capture (CDC) or incremental syncs using a checkpoint file (`state.json`).

It only syncs new/updated records since the last run.

```bash
docker run --pull=always \
  -v "$HOME/PATH_TO_OLAKE_DIRECTORY:/mnt/config" \
  olakego/source-mongodb:latest \
  sync \
  --config /mnt/config/source.json \
  --catalog /mnt/config/streams.json \
  --destination /mnt/config/destination.json \
  --state /mnt/config/state.json
```

</TabItem>

</Tabs>

---

## C. Troubleshooting

| Issue | Possible Cause | Solution |
|-------|----------------|----------|
| Connection failed (UI/CLI) | Wrong host/port, Mongo not running | Check MongoDB is up and accessible. |
| CDC not working (UI/CLI) | Mongo not in replica set / oplog not accessible | Verify replica set is active by running `rs.status()` |
| File not found (CLI) | Not in correct directory while running commands | Make sure both `source.json` and `destination.json` are present in correct directory and the commands are executed while inside the directory. |

