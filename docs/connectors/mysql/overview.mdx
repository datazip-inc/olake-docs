---
title: Overview
description: OLake MySQL Connector description
sidebar_position: 1
---

# MySQL Source

MySQL Source enables data synchronization from MySQL to your [desired destination](../../writers/overview). 

:::info
OLake UI is live (beta)! You can now use the UI to configure your MySQL source, discover streams, and sync data. Check it out at [OLake UI](../../getting-started/olake-ui) regarding how to setup using Docker Compose and running it locally.

![olake-source-mysql](/img/docs/sources/olake-source-mysql.png)

Now, you can use the UI to configure your MySQL source, discover streams, and sync data.
:::

<Tabs>

<TabItem value="mysql-ui" label="Use OLake UI for MySQL" default>

## Create a MySQL Source in OLake UI

Follow the steps below to get started with the MySQL Source using the OLake UI (assuming the OLake UI is running locally on [localhost:8000](localhost:8000)):
1. Navigate to Sources Tab.
2. Click on `+ Create Source`.
3. Select `MySQL` as the source type from Connector type.
4. Fill in the required connection details in the form. For details regarding the connection details, refer to the MySQL Source Configuration section on the right side of UI.
5. Click on `Create ->`
6. OLake will test the source connection and display the results. If the connection is successful, you will see a success message. If there are any issues, OLake will provide error messages to help you troubleshoot.

This will create a MySQL source in OLake, now you can use this source in your [Jobs Pipeline](../../jobs/overview) to sync data from [MySQL](../mysql/overview) to [Apache Iceberg](../../writers/iceberg/overview) or [AWS S3](../../writers/parquet/s3).

## Edit MySQL Source in OLake UI
To edit an existing MySQL source in OLake UI, follow these steps:

1. Navigate to the Sources Tab.
2. Locate the MySQL source you want to edit from `Active Sources` or `Inactive Sources` tabs or using the search bar.
3. Click on the `Edit` button next to the source from the `Actions` tab (3 dots).
4. Update the connection details as needed in the form and Click on `Save Changes`.

:::caution
**Editing a source can break pipeline.**

You will see a notification saying "Due to the editing, the jobs are going to get affected". 

*Editing this source will affect the following jobs that are associated with this source and as a result will fail immediately. Do you still want to edit the source?*

![olake-source-edit-2](/img/docs/sources/olake-source-edit-2.png)
:::

5. OLake will test the updated source connection once you hit confirm on the **Source Editing Caution Modal**. If the connection is successful, you will see a success message. If there are any issues, we will provide error messages to help you troubleshoot.

## Jobs Associated with MySQL Source
In the Source Edit page, you can see the list of jobs that are associated with this source. You can also see the status of each job, whether it is running, failed, or completed and can pause the job from the same screen as well.

![olake-source-associated-job-1](/img/docs/sources/olake-source-associated-job-1.png)

## Delete MySQL Source in OLake UI
To delete an existing MySQL source in OLake UI, follow these steps:
1. Navigate to the Sources Tab.
2. Locate the MySQL source you want to delete from `Active Sources` or `Inactive Sources` tabs or using the search bar.
3. Click on the `Delete` button next to the source from the `Actions` tab (3 dots).

![olake-source-delete-2](/img/docs/sources/olake-source-delete-2.png)

4. A confirmation dialog will appear asking you to confirm the deletion.
5. Click on `Delete` to confirm the deletion.

![olake-source-delete-1](/img/docs/sources/olake-source-delete-1.png)

This will remove the MySQL source from OLake.

:::note
You can also delete a source from the Source Edit page by clicking on the `Delete` button at the bottom of the page. 
:::

</TabItem>

<TabItem value="mysql-cli" label="Use OLake CLI for MySQL">


## To sync data TLDR:
1. **Create a [`source.json`](./config)** with your MySQL connection details.
2. **Create a `destination.json`** with your Writer ([Apache Iceberg](../../writers/iceberg/catalog/overview) / [AWS S3](../../writers/parquet/s3) / [Azure ADLS](../../writers/iceberg/azure) / [Google Cloud Storage](../../writers/iceberg/gcs)) connection details.
3. **Run `discover`** to generate a `streams.json` of available streams.
4. **Run `sync`** to replicate data to your specified destination.


{/* <DocCardList/> */}
Below is an overview of the supported modes and writers for MySQL data replication, along with tables summarizing the details.

### Supported Modes

Our replication process supports various modes to fit different data ingestion needs. 

The **Full Refresh** mode retrieves the entire dataset from MySQL and is ideal for initial data loads or when a complete dataset copy is required. 

In contrast, **CDC (Change Data Capture)** continuously tracks and synchronizes incremental changes in real time, making sure that your destination remains updated with minimal latency. 

The **Incremental** mode is currently under development (WIP).

| Mode                          | Description                                                             |
|-------------------------------|-------------------------------------------------------------------------|
| **Full Refresh**              | Fetches the complete dataset from MySQL.                            |
| **CDC (Change Data Capture)** | Tracks and syncs incremental changes from MySQL in real time.         |
| **Strict CDC (Change Data Capture)** | Tracks only new changes from the current position in the MySQL binlog, without performing an initial backfill. |
| Incremental                   | No, WIP                                                                 |

### Supported Destinations

<SupportedDestinations/>

## Setup and Configuration

To run the MySQL Driver, configure the following files with your specific credentials and settings:

- **`source.json`**: MySQL connection details.  
- **`streams.json`**: List of collections and fields to sync (generated using the *Discover* command).  
- **`write.json`**: Configuration for the destination where the data will be written.

Place these files in your project directory before running the commands.

## Source File 
Add MySQL credentials in following format in `source.json` file as shown [here.](./config#sourcejson-configuration)

### Commands

### Discover Command

The *Discover* command generates json content for `streams.json` file, which defines the schema of the collections to be synced.

#### Usage
To run the Discover command, use the following syntax


<Tabs>

<TabItem value="docker-mongo" label="OLake Docker" default>
<DockerDiscoverMySQL/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalDiscoverMySQL/>
</TabItem>

</Tabs>

<OLakePathInfo/>

## Streams File 
After executing the Discover command, a `streams.json` file is created. Read more about [Streams File](./config#streamsjson-configuration) here.


## Writer File 

Read about about 
1. [Apache Iceberg Destination config](../../writers/iceberg/catalog/overview)
2. S3 writer [here](../../writers/parquet/s3)
3. [Local Filesystem writer](../../writers/parquet/local) 

### Sync Command

The *Sync* command fetches data from MySQL and ingests it into the destination.


<Tabs>

<TabItem value="docker-mongo" label="OLake Docker" default>
<DockerSyncMySQL/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalSyncMySQL/>
</TabItem>

</Tabs>

To run sync with state:

<Tabs>

<TabItem value="docker-mongo" label="OLake Docker" default>
<DockerSyncWithStateMySQL/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalSyncWithStateMySQL/>
</TabItem>

</Tabs>

Find more about state file and its configuration [here.](./config#statejson-configuration)

</TabItem>

</Tabs>


## MySQL to Iceberg Data Type Mapping

When syncing data from MySQL to Iceberg, OLake handles data type conversions to ensure compatibility. Below is a table that outlines how MySQL data types are mapped to Iceberg data types:


| MySQL Data Types | Iceberg Data Type |
| --- | --- |
| `int`, `int unsigned`, `mediumint`, `mediumint unsigned`, `smallint`, `smallint unsigned`, `tinyint`, `tinyint unsigned` | **`int`** |
| `bigint`, `bigint unsigned` | **`bigint`** |
| `float`, `decimal(10,2)` | **`float`** |
| `double`, `double precision`, `real` | **`double`** |
| `datetime`, `timestamp` | **`timestamp`** |
| `char`, `varchar`, `text`, `tinytext`, `mediumtext`, `longtext`, `enum`, `json`, `bit(1)`, `time` | **`string`** |



## Changelog

<details>
  <summary>Expand to review</summary>

| Version     | Date       | Pull Request                                               | Subject                                                                                                                                         |
|:------------|:-----------|:-----------------------------------------------------------|:--------------------------------------------------------|
| v0.0.2            | 14.04.2025             |  https://github.com/datazip-inc/olake/pull/203      |
| v0.0.3            | 31.04.2025             |  https://github.com/datazip-inc/olake/pull/250      |

</details>