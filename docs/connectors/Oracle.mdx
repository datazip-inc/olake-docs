---
title: Oracle
description: OLake Oracle Connector documentation
sidebar_position: 1
---

## Oracle Connector
OLake supports data ingestion from Oracle DB as a source. The connector can be configured using either the OLake UI or the OLake CLI.

<Tabs>

<TabItem value="olake-ui" label="OLake UI" default>
## Setup Prerequisites
- Oracle DB instance available with valid credentials  
- OLake UI installed <!-- TODO: Add OLake UI install page link -->

## Configuration

**1. Navigate to the Source Page**  
Log in to OLake UI. The default credentials are:  
- **Username**: `admin`  
- **Password**: `password`  
    <div style={{textAlign: 'center'}}>
        ![Source tab](/img/docs/sources/oracle/navigate-to-source.gif)
        </div>

**2. Create Oracle Source**  
1. Click **Create Source** on the top right corner.  
2. Select **Oracle** from the connector dropdown and provide a name for this source.  
3. Enter Oracle DB credentials.  
    <div style={{textAlign: 'center'}}>
        ![Source tab](/img/docs/sources/oracle/create-oracle-src.gif)
        </div>
> **Note**: Oracle DB automatically converts lowercase usernames to uppercase, but OLake expects case-sensitive credentials. If connection test fails, retry using an uppercase username.
   4. Once the connection is validated, the Oracle source is created. Jobs can then be configured using this source.  
    <div style={{align : 'center', width: '50%', height: '50%'}}>
        ![Source tab](/img/docs/sources/oracle/source-created.png)
        </div>

## Troubleshooting
#### 1. Sync Failure Due to I/O Timeout

```logs
2025-06-30T14:12:18Z FATAL error occurred while reading records: error occurred while waiting for context groups: failed to get or split chunks: failed to get next row id: read tcp 192.xx.x.xxx:xxxxx->65.x.xxx.xxx:xxxx: i/o timeout
```
**Cause**: Oracle databases often enforce an idle timeout policy, typically between 10 to 15 minutes, after which inactive sessions are terminated. For large tables (e.g., with 10M+ rows), the chunk splitting and row-reading operations may take longer than this default threshold, leading to a connection timeout.
**Solution**: Set the `TIMEOUT` parameter (in seconds) to extend the idle timeout:
- Add it under the `JDBC URL Parameters` textbox while creating or editing the Oracle source.

<div style={{textAlign: 'center'}}>
    ![Source tab](/img/docs/sources/oracle/timeout-olakeui.png)
    </div>


</TabItem>



<TabItem value="olake-cli" label="OLake CLI" default>

## Setup Prerequisites
- Oracle DB instance available with valid credentials
- OLake CLI installed via Docker or Binary <!-- TODO: Add OLake CLI install page links -->

## Configuration

**1. Create Configuration Files**<br/>
    - Once the Olake CLI is setup, create a folder to store configuration files such as `source.json` and `destination.json`.
    
    The `source.json` file for oracle must contain these mandatory fields.
    ```
    {
	"host": "host_name_of_oracle_db",
	"username": "username_of_oracle_db",
	"password": "password_of_oracle_db",
	"service_name": "service_name_of_oracle_db",
    "sid": "sid_of_oracle_db", // either service name or sid can be used
	"port": port_of_oracle_db,
	"ssl": {
		"mode": "ssl_mode_of_oracle_db"
	    }
    }
    ```
    - Similarly `destination.json` file can be created inside this folder, for more information see destination documentaion. <!-- TODO: Destination documentation link must be added here-->

**2. Verify database connection**
    - To verify the `source.json` file this command can be used.

    <Tabs>

    <TabItem value="oracle-cli-docker" label="Using Docker Image" default>
    ```
    docker run \
    -v "[PATH_OF_CONFIG_FOLDER]:/mnt/config" \
    olakego/source-oracle:latest \
    check \
    --config /mnt/config/source.json
    ```
    </TabItem>


    <TabItem value="oracle-cli-binary" label="Using Binary File" default>
    ```
    [PATH_TO_ORACLE_BINARY_FILE]/olake check --config [PATH_TO_CONFIG_FOLDER]/source.json
    ```   
 
    </TabItem>

    </Tabs>
    > **Note**: Oracle DB automatically converts the lowercase username to uppercase, but OLake expects case sensitive credentials.  so if testing the connection fails in OLake try changing the username to all uppercase.
    - If OLake is able to connect with Oracle DB `{"connectionStatus":{"status":"SUCCEEDED"},"type":"CONNECTION_STATUS"}` response is returned.
   
**3. Run discover command** <br/>
The discover command generates a streams.json file containing metadata for all accessible Oracle tables.
    <Tabs>

    <TabItem value="oracle-cli-docker" label="Using Docker Image" default>
    ```
    docker run \
    -v "[PATH_OF_CONFIG_FOLDER]:/mnt/config" \
    olakego/source-oracle:latest \
    discover \
    --config /mnt/config/source.json
    ```
    </TabItem>


    <TabItem value="oracle-cli-binary" label="Using Binary File" default>
    ```
    [PATH_TO_ORACLE_BINARY_FILE]/olake discover --config [PATH_TO_CONFIG_FOLDER]/source.json
    ```   
 
    </TabItem>

    </Tabs>

   - Once streams.json is properly configured, data can be synchronized.
    The `streams.json` file looks like this:
    ```
    {
    "selected_streams": {
        "TABLE-OWNER": [
            {
                "partition_regex": "",
                "stream_name": "EXAMPLE-TABLE",
                "normalization": true
            }]},
             "streams": [{
                "stream": {
                "name": "EXAMPLE-TABLE",
                "namespace": "TABLE-OWNER",
                "type_schema": {
                    "properties": {
                        "id": {"type": ["integer_small"]},
                        "name": {"type": ["string","null"]},
                        "created_at": {"type": ["timestamp_micro"]}}},
                "supported_sync_modes": ["full_refresh","incremental"],
                "source_defined_primary_key": ["id"],
                "available_cursor_fields": [id,name,created_at],
                "sync_mode": "full_refresh",
                "cursor_field" : "primary_cursor_field:secondary_cursor_field" 
                // cursor field is only required in case of incremental sync, also secondary_cursor_field is optional    
                }}]}
    ```

**4. Run sync command**
Once configuring the `streams.json` file is done. You can start the sync using these commands.
<Tabs>

    <TabItem value="oracle-cli-docker" label="Using Docker Image" default>
    **Sync command**
    ```
    docker run \
    -v "[PATH_OF_CONFIG_FOLDER]:/mnt/config" \
    olakego/source-oracle:latest \
    sync \
    --config /mnt/config/source.json \
    --catalog /mnt/config/streams.json \
    --destination /mnt/config/destination.json
    ```

    **Sync with state command**
    ```
    docker run \
    -v "[PATH_OF_CONFIG_FOLDER]:/mnt/config" \
    olakego/source-oracle:latest \
    sync \
    --config /mnt/config/source.json \
    --catalog /mnt/config/streams.json \
    --destination /mnt/config/destination.json \
    --state /mnt/config/state.json
    ```
    </TabItem>


    <TabItem value="oracle-cli-binary" label="Using Binary File" default>
    **Sync command**
    ```
    [PATH_TO_ORACLE_BINARY_FILE]/olake sync \
    --config [PATH_TO_CONFIG_FOLDER]/config.json \
    --catalog [PATH_TO_CONFIG_FOLDER]/streams.json \
    --destination [PATH_TO_CONFIG_FOLDER]/write.json
    ```

    **Sync with state command**
    ```
    [PATH_TO_ORACLE_BINARY_FILE]/olake sync \
    --config [PATH_TO_CONFIG_FOLDER]/config.json \
    --catalog [PATH_TO_CONFIG_FOLDER]/streams.json \
    --destination [PATH_TO_CONFIG_FOLDER]/write.json \
    --state [PATH_TO_CONFIG_FOLDER]/state.json
    ```
    </TabItem>

    </Tabs>


## Troubleshooting
#### 1. Sync Failure Due to I/O Timeout

```logs
2025-06-30T14:12:18Z FATAL error occurred while reading records: error occurred while waiting for context groups: failed to get or split chunks: failed to get next row id: read tcp 192.xx.x.xxx:xxxxx->65.x.xxx.xxx:xxxx: i/o timeout
```
**Cause**: Oracle databases often enforce an idle timeout policy, typically between 10 to 15 minutes, after which inactive sessions are terminated. For large tables (e.g., with 10M+ rows), the chunk splitting and row-reading operations may take longer than this default threshold, leading to a connection timeout.

**Solution**: Set the `TIMEOUT` parameter (in seconds) to extend the idle timeout:
Add it under the `jdbc_url_params` field in your `config.json`.
```json
"jdbc_url_params": {
    "TIMEOUT": "86400" /* Timeout in seconds; here, 24 hours (24 × 60 × 60) */
}
```
</TabItem>

</Tabs>