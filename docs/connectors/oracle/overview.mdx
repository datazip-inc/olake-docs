---
title: Overview
description: OLake Oracle Connector description
sidebar_position: 1
---

# Oracle Source

Oracle Source enables data synchronization from Oracle to your [desired destination](../../writers/overview). 

:::info
OLake UI is live (beta)! You can now use the UI to configure your Oracle source, discover streams, and sync data. Check it out at [OLake UI](../../getting-started/olake-ui) regarding how to setup using Docker Compose and running it locally.

![olake-source-postgres](/img/docs/sources/olake-source-postgres.png)

Now, you can use the UI to configure your Oracle source, discover streams, and sync data.
:::

<Tabs>

<TabItem value="oracle-ui" label="Use OLake UI for Oracle" default>

## Create a Oracle Source in OLake UI

Follow the steps below to get started with the Oracle Source using the OLake UI (assuming the OLake UI is running locally on [localhost:8000](localhost:8000)):
1. Navigate to Sources Tab.
2. Click on `+ Create Source`.
3. Select `Oracle` as the source type from Connector type.
4. Fill in the required connection details in the form. For details regarding the connection details, refer to the Oracle Source Configuration section on the right side of UI.
5. Click on `Create ->`
6. OLake will test the source connection and display the results. If the connection is successful, you will see a success message. If there are any issues, OLake will provide error messages to help you troubleshoot.

This will create a Oracle source in OLake, now you can use this source in your [Jobs Pipeline](../../jobs/overview) to sync data from [Oracle](../oracle/overview) to [Apache Iceberg](../../writers/iceberg/overview) or [AWS S3](../../writers/parquet/s3).

## Edit Oracle Source in OLake UI
To edit an existing Oracle source in OLake UI, follow these steps:

1. Navigate to the Sources Tab.
2. Locate the Oracle source you want to edit from `Active Sources` or `Inactive Sources` tabs or using the search bar.
3. Click on the `Edit` button next to the source from the `Actions` tab (3 dots).
4. Update the connection details as needed in the form and Click on `Save Changes`.

:::caution
**Editing a source can break pipeline.**

You will see a notification saying "Due to the editing, the jobs are going to get affected". 

*Editing this source will affect the following jobs that are associated with this source and as a result will fail immediately. Do you still want to edit the source?*

![olake-source-edit-2](/img/docs/sources/olake-source-edit-2.png)
:::

5. OLake will test the updated source connection once you hit confirm on the **Source Editing Caution Modal**. If the connection is successful, you will see a success message. If there are any issues, we will provide error messages to help you troubleshoot.

## Jobs Associated with Oracle Source
In the Source Edit page, you can see the list of jobs that are associated with this source. You can also see the status of each job, whether it is running, failed, or completed and can pause the job from the same screen as well.

![olake-source-associated-job-1](/img/docs/sources/olake-source-associated-job-1.png)

## Delete Oracle Source in OLake UI
To delete an existing Oracle source in OLake UI, follow these steps:
1. Navigate to the Sources Tab.
2. Locate the Oracle source you want to delete from `Active Sources` or `Inactive Sources` tabs or using the search bar.
3. Click on the `Delete` button next to the source from the `Actions` tab (3 dots).

![olake-source-delete-2](/img/docs/sources/olake-source-delete-2.png)

4. A confirmation dialog will appear asking you to confirm the deletion.
5. Click on `Delete` to confirm the deletion.

![olake-source-delete-1](/img/docs/sources/olake-source-delete-1.png)

This will remove the Oracle source from OLake.

:::note
You can also delete a source from the Source Edit page by clicking on the `Delete` button at the bottom of the page. 
:::

</TabItem>

<TabItem value="oracle-cli" label="Use OLake CLI for Oracle">


## To sync data TLDR:
1. **Create a [`source.json`](./config)** with your Oracle connection details.
2. **Create a `destination.json`** with your Writer ([Apache Iceberg](../../writers/iceberg/catalog/overview) / [AWS S3](../../writers/parquet/s3) / [Azure ADLS](../../writers/iceberg/azure) / [Google Cloud Storage](../../writers/iceberg/gcs)) connection details.
3. **Run `discover`** to generate a `streams.json` of available streams.
4. **Run `sync`** to replicate data to your specified destination.


## Features

- Efficient data chunking based on ROWID for optimal performance
- Dynamic chunk size calculation based on table size
- Proper handling of SCN (System Change Number) for data consistency


## Oracle Driver

The Oracle Driver enables data synchronization from Oracle to your desired destination. 

Below is an overview of the supported modes and writers for Oracle data replication, along with tables summarizing the details.

### Supported Modes

Our replication process supports various modes to fit different data ingestion needs. 

The **Full Refresh** mode retrieves the entire dataset from Oracle and is ideal for initial data loads or when a complete dataset copy is required. 

| Mode                          | Description                                                             |
|-------------------------------|-------------------------------------------------------------------------|
| **Full Refresh**              | Fetches the complete dataset from Oracle.                            |


### Supported Destinations

<SupportedDestinations/>

## Setup and Configuration

To run the Oracle Driver, configure the following files with your specific credentials and settings:

- **`source.json`**: Oracle connection details.  
- **`streams.json`**: List of collections and fields to sync (generated using the *Discover* command).  
- **`write.json`**: Configuration for the destination where the data will be written.

Place these files in your project directory before running the commands.

## Source File 
Add Oracle credentials in following format in `source.json` file as shown [here.](./config#sourcejson-configuration)

### Commands

### Discover Command

The *Discover* command generates json content for `streams.json` file, which defines the schema of the collections to be synced.

#### Usage
To run the Discover command, use the following syntax

<Tabs>

<TabItem value="docker-oracle" label="OLake Docker" default>
<DockerDiscoverOracle/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalDiscoverOracle/>
</TabItem>

</Tabs>

## Streams File 
After executing the Discover command, a `streams.json` file is created. Read more about [Streams File](./config#streamsjson-configuration) here.


## Writer File 

Read about about :
1. [Apache Iceberg Destination config](../../writers/iceberg/catalog/overview)
2. [S3 writer](../../writers/parquet/s3)
3. [Local Filesystem writer](../../writers/parquet/local) 

### Sync Command

The *Sync* command fetches data from Oracle and ingests it into the destination.

<Tabs>

<TabItem value="docker-oracle" label="OLake Docker" default>
<DockerSyncOracle/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalSyncOracle/>
</TabItem>

</Tabs>

{/* To run sync with state:


<Tabs>

<TabItem value="docker-oracle" label="OLake Docker" default>
<DockerSyncWithStateOracle/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalSyncWithStateOracle/>
</TabItem>

</Tabs> */}

{/* Find more about state file and its configuration [here.](./config#statejson-configuration) */}


</TabItem>
</Tabs>



{/* ## Oracle to Iceberg Data Type Mapping

When syncing data from Oracle to Iceberg, OLake handles data type conversions to ensure compatibility. Below is a table that outlines how Oracle data types are mapped to Iceberg data types:

| Oracle Data Types | Iceberg Data Type |
| --- | --- |
| `int`, `int2`, `int4`, `smallint`, `integer`, `serial`, `serial2`, `serial4` | **`int`** |
| `bigint`, `bigserial`, `int8`, `serial8` | **`bigint`** |
| `float`, `float4`, `real`, `numeric` | **`float`** |
| `double precision`, `float8` | **`double`** |
| `boolean` | **`boolean`** |
| `date`, `timestamp without time zone`, `timestamp with time zone` | **`timestamp`** |
| `box`, `bpchar`, `char`, `character`, `character varying`, `json`, `jsonb`, `jsonpath`, `name`, `numrange`, `path`, `text`, `tid`, `tsquery`, `tsrange`, `tstzrange`, `uuid`, `varbit`, `varchar`, `xml`, `inet`, `bit`, `int2vector`, `daterange`, `time with time zone`, `time without time zone` | **`string`** |
 */}

{/* ## Changelog

<details>
  <summary>Expand to review</summary>

| Version     | Date       | Pull Request                                               | Subject                                                                                                                                         |
|:------------|:-----------|:-----------------------------------------------------------|:--------------------------------------------------------|
| v0.0.3            | 14.04.2025             |  https://github.com/datazip-inc/olake/pull/203      |
| v0.0.4            | 31.04.2025             |  https://github.com/datazip-inc/olake/pull/250      |

</details> */}
