---
title: Overview
description: OLake Postgres Connector description
sidebar_position: 1
---

# Postgres Source

Postgres Source enables data synchronization from Postgres to your [desired destination](../../writers/overview). 

:::info
OLake UI is live (beta)! You can now use the UI to configure your Postgres source, discover streams, and sync data. Check it out at [OLake UI](../../getting-started/olake-ui) regarding how to setup using Docker Compose and running it locally.

![olake-source-postgres](/img/docs/sources/olake-source-postgres.png)

Now, you can use the UI to configure your Postgres source, discover streams, and sync data.
:::

<Tabs>

<TabItem value="postgres-ui" label="Use OLake UI for Postgres" default>

## Create a Postgres Source in OLake UI

Follow the steps below to get started with the Postgres Source using the OLake UI (assuming the OLake UI is running locally on [localhost:8000](localhost:8000)):
1. Navigate to Sources Tab.
2. Click on `+ Create Source`.
3. Select `Postgres` as the source type from Connector type.
4. Fill in the required connection details in the form. For details regarding the connection details, refer to the Postgres Source Configuration section on the right side of UI.
5. Click on `Create ->`
6. OLake will test the source connection and display the results. If the connection is successful, you will see a success message. If there are any issues, OLake will provide error messages to help you troubleshoot.

This will create a Postgres source in OLake, now you can use this source in your [Jobs Pipeline](../../jobs/overview) to sync data from [Postgres](../postgres/overview) to [Apache Iceberg](../../writers/iceberg/overview) or [AWS S3](../../writers/parquet/s3).

## Edit Postgres Source in OLake UI
To edit an existing Postgres source in OLake UI, follow these steps:

1. Navigate to the Sources Tab.
2. Locate the Postgres source you want to edit from `Active Sources` or `Inactive Sources` tabs or using the search bar.
3. Click on the `Edit` button next to the source from the `Actions` tab (3 dots).
4. Update the connection details as needed in the form and Click on `Save Changes`.

:::caution
**Editing a source can break pipeline.**

You will see a notification saying "Due to the editing, the jobs are going to get affected". 

*Editing this source will affect the following jobs that are associated with this source and as a result will fail immediately. Do you still want to edit the source?*

![olake-source-edit-2](/img/docs/sources/olake-source-edit-2.png)
:::

5. OLake will test the updated source connection once you hit confirm on the **Source Editing Caution Modal**. If the connection is successful, you will see a success message. If there are any issues, we will provide error messages to help you troubleshoot.

## Jobs Associated with Postgres Source
In the Source Edit page, you can see the list of jobs that are associated with this source. You can also see the status of each job, whether it is running, failed, or completed and can pause the job from the same screen as well.

![olake-source-associated-job-1](/img/docs/sources/olake-source-associated-job-1.png)

## Delete Postgres Source in OLake UI
To delete an existing Postgres source in OLake UI, follow these steps:
1. Navigate to the Sources Tab.
2. Locate the Postgres source you want to delete from `Active Sources` or `Inactive Sources` tabs or using the search bar.
3. Click on the `Delete` button next to the source from the `Actions` tab (3 dots).

![olake-source-delete-2](/img/docs/sources/olake-source-delete-2.png)

4. A confirmation dialog will appear asking you to confirm the deletion.
5. Click on `Delete` to confirm the deletion.

![olake-source-delete-1](/img/docs/sources/olake-source-delete-1.png)

This will remove the Postgres source from OLake.

:::note
You can also delete a source from the Source Edit page by clicking on the `Delete` button at the bottom of the page. 
:::

</TabItem>

<TabItem value="postgres-cli" label="Use OLake CLI for Postgres">


## To sync data TLDR:
1. **Create a [`source.json`](./config)** with your Postgres connection details.
2. **Create a `destination.json`** with your Writer ([Apache Iceberg](../../writers/iceberg/catalog/overview) / [AWS S3](../../writers/parquet/s3) / [Azure ADLS](../../writers/iceberg/azure) / [Google Cloud Storage](../../writers/iceberg/gcs)) connection details.
3. **Run `discover`** to generate a `streams.json` of available streams.
4. **Run `sync`** to replicate data to your specified destination.


## Features

- Resumable Full Load: Supports restarting full loads without reprocessing all data.
- Fast Full Load via Chunking:
  • CTID-based chunking
  • Single split-column chunking
  • Evenly distributed chunks (for int/float PKs)
  • Uneven chunking support
- WAL2JSON-based CDC Sync for incremental updates. 

:::caution
Currently plugin of `pgoutput` as replication slot is not supported, only `WAL2JSON` is supported.
:::

- New streams are automatically synced when added.
- LSN mismatch handling triggers a full resync.

## Postgres Driver

The Postgres Driver enables data synchronization from Postgres to your desired destination. 

{/* <DocCardList/> */}
Below is an overview of the supported modes and writers for Postgres data replication, along with tables summarizing the details.

### Supported Modes

Our replication process supports various modes to fit different data ingestion needs. 

The **Full Refresh** mode retrieves the entire dataset from Postgres and is ideal for initial data loads or when a complete dataset copy is required. 

In contrast, **CDC (Change Data Capture)** continuously tracks and synchronizes incremental changes in real time, making sure that your destination remains updated with minimal latency. 

The **Incremental** mode is currently under development (WIP).

| Mode                          | Description                                                             |
|-------------------------------|-------------------------------------------------------------------------|
| **Full Refresh**              | Fetches the complete dataset from Postgres.                            |
| **CDC (Change Data Capture)** | Tracks and syncs incremental changes from Postgres in real time.         |
| **Strict CDC (Change Data Capture)** | Tracks only new changes from the current position in the Postgres WAL, without performing an initial backfill. |
| Incremental                   | No, WIP                                                                 |

### Supported Destinations

<SupportedDestinations/>

## Setup and Configuration

To run the Postgres Driver, configure the following files with your specific credentials and settings:

- **`source.json`**: Postgres connection details.  
- **`streams.json`**: List of collections and fields to sync (generated using the *Discover* command).  
- **`write.json`**: Configuration for the destination where the data will be written.

Place these files in your project directory before running the commands.

## Source File 
Add Postgres credentials in following format in `source.json` file as shown [here.](./config#sourcejson-configuration)

### Commands

### Discover Command

The *Discover* command generates json content for `streams.json` file, which defines the schema of the collections to be synced.

#### Usage
To run the Discover command, use the following syntax

<Tabs>

<TabItem value="docker-postgres" label="OLake Docker" default>
<DockerDiscoverPostgres/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalDiscoverPostgres/>
</TabItem>

</Tabs>

## Streams File 
After executing the Discover command, a `streams.json` file is created. Read more about [Streams File](./config#streamsjson-configuration) here.


## Writer File 

Read about about :
1. [Apache Iceberg Destination config](../../writers/iceberg/catalog/overview)
2. [S3 writer](../../writers/parquet/s3)
3. [Local Filesystem writer](../../writers/parquet/local) 

### Sync Command

The *Sync* command fetches data from Postgres and ingests it into the destination.

<Tabs>

<TabItem value="docker-postgres" label="OLake Docker" default>
<DockerSyncPostgres/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalSyncPostgres/>
</TabItem>

</Tabs>

To run sync with state:


<Tabs>

<TabItem value="docker-postgres" label="OLake Docker" default>
<DockerSyncWithStatePostgres/>
</TabItem>

<TabItem value="docker-local" label="Locally run OLake" default>
<LocalSyncWithStatePostgres/>
</TabItem>

</Tabs>

Find more about state file and its configuration [here.](./config#statejson-configuration)


</TabItem>
</Tabs>



## PostgreSQL to Iceberg Data Type Mapping

When syncing data from PostgreSQL to Iceberg, OLake handles data type conversions to ensure compatibility. Below is a table that outlines how PostgreSQL data types are mapped to Iceberg data types:

| PostgreSQL Data Types | Iceberg Data Type |
| --- | --- |
| `int`, `int2`, `int4`, `smallint`, `integer`, `serial`, `serial2`, `serial4` | **`int`** |
| `bigint`, `bigserial`, `int8`, `serial8` | **`bigint`** |
| `float`, `float4`, `real`, `numeric` | **`float`** |
| `double precision`, `float8` | **`double`** |
| `boolean` | **`boolean`** |
| `date`, `timestamp without time zone`, `timestamp with time zone` | **`timestamp`** |
| `box`, `bpchar`, `char`, `character`, `character varying`, `json`, `jsonb`, `jsonpath`, `name`, `numrange`, `path`, `text`, `tid`, `tsquery`, `tsrange`, `tstzrange`, `uuid`, `varbit`, `varchar`, `xml`, `inet`, `bit`, `int2vector`, `daterange`, `time with time zone`, `time without time zone` | **`string`** |


## Changelog

<details>
  <summary>Expand to review</summary>

| Version     | Date       | Pull Request                                               | Subject                                                                                                                                         |
|:------------|:-----------|:-----------------------------------------------------------|:--------------------------------------------------------|
| v0.0.3            | 14.04.2025             |  https://github.com/datazip-inc/olake/pull/203      |
| v0.0.4            | 31.04.2025             |  https://github.com/datazip-inc/olake/pull/250      |



</details>