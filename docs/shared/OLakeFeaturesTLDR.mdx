
### 1. OLake native features

1. **Open data formats** – OLake writes raw Parquet and fully ACID snapshots in [Apache Iceberg](/docs/writers/iceberg/overview) so your lakehouse stays engine-agnostic.
2. **Iceberg writer** – The dedicated [Iceberg Java Writer](/docs/writers/iceberg/overview) (migrating to [Iceberg Go writer](https://github.com/datazip-inc/olake/pull/337)) produces exactly-once, rollback-ready Iceberg v2 tables.
3. **Smart partitioning** – We support both [Iceberg partitioning rules](/docs/writers/iceberg/partitioning) and[AWS S3 partitioning](/docs/writers/parquet/partitioning) for Parquet for fast scans and efficient querying.
4. **Parallelised chunking** – OLake splits big tables into smaller chunks, slashing total faster processing and parallel execution.
5. **Change Data Capture** – We capture WALs for Postgres, binlogs for MongoDB and oplogs for MySQL in near real-time to keep the lake fresh without reloads.
6. **[Schema evolution & datatype changes](/docs/features/schema)** – Column adds, drops and type promotions are auto-detected and written per Iceberg v2 spec, so pipelines never break.
7. **Stateful, resumable syncs** – If a [job](/docs/jobs/overview) crashes (or is paused), OLake resumes from the last committed checkpoint—no manual fixes needed.
8. **Back-off & retries** – OLake supports backoff retry count, meaning, if a sync fails, it will retry the sync after a certain period of time.
9. **Synchronization Modes**: OLake supports both full, CDC (Change Data Capture) and strict CDC (Tracks only new changes from the current position in the MongoDB change stream, without performing an initial backfill) synchronization modes. Incremental sync is a work in progress and will be released soon.
10. **Level-1 JSON flattening** – Nested JSON fields are optionally expanded into top-level columns for easier SQL.
11. **Airflow-first orchestration** – Drop our Docker images into your DAGs ([EC2](/blog/olake-airflow-on-ec2) or [Kubernetes](/docs/install/kubernetes)) and drive syncs via Airflow.
12. **Developer playground** – A one-click [OLake + Iceberg sandbox](/docs/playground/olake-iceberg-presto) lets you experiment locally with Trino, Spark, Flink or Snowflake readers.


### 2. Source-level features

1. **PostgreSQL** – Full loads and `WAL-based` CDC for RDS, Aurora, Supabase, etc. See the [Postgres connector](/docs/connectors/postgres/overview).
2. **MySQL** – Full loads plus `binlog` CDC for MySQL RDS, Aurora and older community versions. See the [MySQL connector](/docs/connectors/mysql/overview).
3. **MongoDB** – High-throughput `oplog` capture for sharded or replica-set clusters. See the [MongoDB connector](/docs/connectors/mongodb/overview).
4. **Optimised chunking strategies** –
    - **MongoDB** – `Split-Vector`, `Bucket-Auto` & `Timestamp`; details in the blog [What Makes OLake Fast](http://olake.io/blog/what-makes-olake-fast).
    - **MySQL** – Range splits driven by `LIMIT/OFFSET` next-query logic.
    - **Postgres** – `CTID` ranges, `batch-size` column splits or `next-query` paging.
5. **Work-in-progress connectors** –
    - **S3 source** – [GitHub issue #86](https://github.com/datazip-inc/olake/issues/86)
    - **Kafka** – [PR #339](https://github.com/datazip-inc/olake/pull/339)

6. We map each of database datatypes to respective Iceberg datatypes so your source schema remains more or less unaffected by the type conversion from a source database to Iceberg. See for:
    - [Postgres type mapping](/docs/connectors/postgres/overview#postgres-to-iceberg-data-type-mapping)
    - [MySQL type mapping](/docs/connectors/mysql/overview#mysql-to-iceberg-data-type-mapping)
    - [MongoDB type mapping](/docs/connectors/mongodb/overview#mongodb-to-iceberg-data-type-mapping)

### 3. Destination-level features

1. **Apache Iceberg** – Primary target format, can write to AWS S3, Azure, GCS: see [Iceberg Writer docs](/docs/writers/iceberg/overview).
   
2. **Catalog options:**
    - **AWS Glue** – [Glue catalog guide](/docs/writers/iceberg/catalog/glue)
    - **REST catalog** – [REST guide](/docs/writers/iceberg/catalog/rest) with sub-sections for [Gravitino](/docs/writers/iceberg/catalog/rest#using-gravitino), [Nessie](/docs/writers/iceberg/catalog/rest#using-nessie), [Polaris](/docs/writers/iceberg/catalog/rest#using-polaris), [Unity](/docs/writers/iceberg/catalog/rest#using-unity) and [LakeKeeper](/docs/writers/iceberg/catalog/rest#using-lakekeeper)
    - **Hive Metastore** – [Hive catalog guide](/docs/writers/iceberg/catalog/hive)
    - **JDBC** – [JDBC catalog guide](/docs/writers/iceberg/catalog/jdbc)
    - **S3 Table Bucket (`SigV4`)** – [How-to](/docs/writers/iceberg/s3-tables)
    - **Unity Catalog (Databricks)** – [How-to](/docs/writers/iceberg/unity-catalog)

3. **Plain Parquet** – Write partitioned Parquet to S3 or Google Cloud Storage (GCS) with the [Parquet Writer](/docs/writers/parquet/s3).
4. **Query engines** – Any Iceberg v2-aware tool (Trino, Spark, Flink, Snowflake, etc.) can query OLake outputs immediately. See [here](/docs/getting-started/overview) for more

### 4. Upcoming features

1. **Telemetry hooks** – Segment IO & Mixpanel integration ([PR #290](https://github.com/datazip-inc/olake/pull/290)).
2. **Universal MySQL CDC** – MariaDB, Percona & TiDB support ([PR #359](https://github.com/datazip-inc/olake/pull/359)).
3. **Incremental sync** – Rolling out for [MongoDB PR #268](https://github.com/datazip-inc/olake/pull/268), then Postgres and MySQL.
4. **Roadmap tracker** – See the live [OLake roadmap](/docs/roadmap).
