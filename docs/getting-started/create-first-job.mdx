---
title: Create your first job
description: Create your first OLake job
sidebar_position: 6
---

# Create Your First Job

This guide is for end-users who want to replicate data between the various sources and destinations OLake supports.

Using the OLake UI, you'll configure a [source](/docs/connectors/overview), set up a [destination](/docs/writers/overview), and create a job to move data between them all through a simple point-and-click interface with no extra setup.

By the end of this tutorial, you’ll have a complete replication workflow running in OLake. Jump straight to the [tutorial](#tutorial-creating-a-job).

## Prerequisites

###  What is a Job?
A job in OLake is a pipeline that defines how data should be synchronized from a **source** (where your data comes from) to a **destination** (where your data goes). 

Sources and destinations can be:

- **New** - configured during job creation.
- **Existing** - already set up and reused across multiple jobs.

### Two ways to create a Job?

#### 1. Job-first workflow (guided setup)
Start from the **Jobs** page and set up everything in one flow.
1. Go to **Jobs** in the left menu and click **Create Job**.
1. Configure the **source**.
1. Configure the **destination**.
1. Configure streams, schedule, and save.

#### 2. Resource-first workflow (prepare resources in advance)
Set up your source and destination first, then link them in a job.
1. Create a source from the **Sources** page.
1. Create a destination from the **Destinations** page.
1. Go to **Jobs → Create Job**, and select the existing source and destination.
1. Configure streams, schedule, and save.

:::tip
The two methods achieve the same result. Choose **Job-first** if you want a guided setup in one go. 
Choose **Resource-first** if your source and destination are already configured, or if you prefer to prepare them in advance.
:::

## Tutorial: Creating a Job
In this guide, we’ll use the **Job-first workflow** to set up a job from configuring the source and destination to running it.

First things first, every job needs a source and a destination before it can run. 
For this demonstration, we’ll use **Postgres** as the source and **Iceberg with a Glue catalog** as the destination. 
For other supported options checkout: [source](/docs/connectors/overview) and [destination](/docs/writers/overview).

Let's get started!

### Create a New Job
Navigate to **Jobs** section and select **+ Create Job** button in the top right corner. This opens the Job creation wizard, starting with the **source configuration** step.

![Job page](../../static/img/docs/getting-started/create-your-first-job/job-create.png)

### Configure Source

Since we’re following the **Job-first workflow**, select the **Set up a new source** option.

For this guide, choose **Postgres** from the connector dropdown, and keep the **OLake version** set to the latest stable version. 

If you want to use a different source connector, check out the full list of supported sources in the [Sources section](/docs/connectors/overview) of our documentation.

![Job source creation](../../static/img/docs/getting-started/create-your-first-job/job-source-connector.png)

Give your source a descriptive name, then fill in the required Postgres connection details in the Endpoint Config form.

![Job source creation](../../static/img/docs/getting-started/create-your-first-job/job-source-config.png)

Once the test connection succeeds, OLake shows a success message and takes you to the destination configuration step. 

:::note
If you plan to enable CDC (Change Data Capture), make sure a replication slot already exists on your Postgres database. 
You can learn how to check or create one in our [Replication Slot Guide](/docs/connectors/postgres/setup/generic).
:::

### Configure Destination

Similarly, here we’ll be using **Iceberg** with **AWS Glue Catalog** as the destination.  
If you want to use a different destination connector, check out the full list of supported destinations in the **Destinations** section of our documentation. 

For this guide, select **Apache Iceberg** from the connector dropdown, and keep the **OLake version** set to the latest stable version.

![Job destination creation](../../static/img/docs/getting-started/create-your-first-job/job-dest-connector.png)

Choose the catalog as **AWS Glue** from the Catalog dropdown.

![Job destination catalog](../../static/img/docs/getting-started/create-your-first-job/job-dest-catalog.png)

Give your destination a descriptive name, then fill in the required connection details in the Endpoint Config form.

![Job destination config](../../static/img/docs/getting-started/create-your-first-job/job-dest-config.png)

Once the test connection succeeds, OLake shows a success message and takes you to the streams configuration step. 

### Configure Streams

The **Streams** page is where you select which streams to replicate to the destination.
Here, you can choose your preferred [sync mode](/edit/later) and configure [partitioning](/edit/later) as well as other stream-level settings here.

![Job streams page](../../static/img/docs/getting-started/create-your-first-job/job-streams.png)

For this guide, we’ll configure the following:
- Replicate the `fivehundred` stream (name of the table).
- Use **Full Refresh + CDC** as the sync mode.
- Enable **data normalisation**.
- Replicate only data where `dropoff_datetime` >= `2010-01-01 00:00:00` (basically data from 2010 onwards).
- Partition the data by the **year** extracted from a timestamp column in the selected stream.
- Run the sync every day at 12:00 AM.


Let's start by selecting the `fivehundred` (or any stream from your source) stream by checking its checkbox to include it in the replication.
Click the stream name to open the stream-level settings panel on the right side.
In the panel, set the **sync mode** to **Full Refresh + CDC**, and enable **Normalisation** by toggling the switch on.

![Job streams selection](../../static/img/docs/getting-started/create-your-first-job/job-stream-select.png)

:::info
To learn more about sync modes, refer to our [Sync Modes Guide](/edit/later) in the documentation.
:::

To partition the data, click the **Partitioning** tab and configure it based on the required details.
In our case, the `fivehundred` stream has a timestamp column named `dropoff_datetime`, which we will partition by **year**. Learn more about partitioning in the [Partitioning Guide](/edit/later).

![Job stream partitioning](../../static/img/docs/getting-started/create-your-first-job/job-stream-partition.png)

To replicate only data from 2010 onwards, we'll use a **Data Filter** to filter the data based on the `dropoff_datetime` column. 
Make sure the **Value** provided is in the same format as the column schema.

![Job stream data filter](../../static/img/docs/getting-started/create-your-first-job/job-data-filter.png)


After completing all configurations, click **Next** to proceed to the final step in the job creation process, **Job Config**.

### Schedule Job

Give your job a descriptive name. For this guide, set the **Frequency** dropdown to **Every Day** and choose **12:00 AM** as the **Time**.

![Job schedule](../../static/img/docs/getting-started/create-your-first-job/job-schedule.png)

Once configured, click **Create Job** in the bottom-right corner. Tada!, you’ve successfully created your first job!

![Job create](../../static/img/docs/getting-started/create-your-first-job/job-creation-success.png)

The sync will start at the next occurrence of the configured time. You can also start the sync manually. Go to the **Jobs** section, find your created job, click the **options** menu, and select **Sync Now**.

![Sync now](../../static/img/docs/getting-started/create-your-first-job/job-sync-now.png)

You can verify the sync status by checking the badge at the right end of the job row. Possible statuses include **Running**, **Failed**, and **Completed**. 
You can also monitor the sync logs by selecting **Job Logs and History** from the job options menu.

- Job running.
![Job running](../../static/img/docs/getting-started/create-your-first-job/job-running.png)

- Job completed.
![Job completed](../../static/img/docs/getting-started/create-your-first-job/job-success.png)


Yay! The sync is complete, and our data has been replicated to Iceberg exactly as we configured it.


![Amazon S3](../../static/img/docs/getting-started/create-your-first-job/job-data-s3.png)

### Manage Your Job 
Once your job is created, you can manage it from the **Jobs** page using the **Actions** menu **(⋮).**

Here’s what each option does:

#### 1. Sync Now
Run the job immediately without waiting for the next scheduled time.

#### 2. Edit Streams
Use this option to modify which streams are included in your job and adjust their replication settings.
When you click **Edit Streams** you’ll be redirected to the **Stream Configuration** page.

Here you can:

- **Add new streams** from your source.
- **Change the sync mode** for selected streams.
- **Adjust partitioning** or **normalisation** for newly added streams.
- You can also navigate to **Source** and **Destination** settings using the stepper at the top-right of the page. 

![Edit streams](../../static/img/docs/getting-started/create-your-first-job/job-edit-streams-page.png)

- By default, source and destination editing is locked click **Edit** to unlock them.

![Edit streams destination](../../static/img/docs/getting-started/create-your-first-job/job-edit-destination.png)


:::note
You cannot directly change the **normalisation**, **data filter**, or **partition scheme** for streams already in the job. To update these:
1. Unselect the stream.
1. Save the job.
1. Reopen **Edit Streams** and re-add the stream with the updated settings
:::

#### 3. Pause Job
Stops the job from running until resumed. Paused jobs appear under **Inactive Jobs**. Resume them anytime from the **Inactive Jobs** tab.

![Pause job](../../static/img/docs/getting-started/create-your-first-job/job-resume.png)

#### 4. Job Logs & History
This page lets you view and monitor a job’s sync history and logs. You’ll see a list of all current and past job runs.
To view logs for a specific run, click **View Logs** in the Actions column.

![Job logs](../../static/img/docs/getting-started/create-your-first-job/view-logs.png)

Once you click **View Logs**, you'll see the logs for the selected job run.

![Job logs](../../static/img/docs/getting-started/create-your-first-job/logs-page.png)

#### 5. Job settings
Here, you can edit the job’s name, frequency, and other configuration settings.
You can also pause or delete the job.

When a job is deleted, its associated source and destination are automatically moved to the inactive state, provided they are not being used by any other job.

![Job settings](../../static/img/docs/getting-started/create-your-first-job/job-settings.png)







