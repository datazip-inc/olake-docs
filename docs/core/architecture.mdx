---
title: Architecture
description: Architecture
sidebar_position: 1
---


This will act as a base on top of which connectors will be developed

## Whats ROI for users worldwide?

- 10x better datasync from databases to Lakehouses (5x faster & 5x cost efficient averagely)
    - Parallel first full load & incremental sync

- Apache-2 license
    - This is commoditised already.
    - This comes with pro of easy visibility and distribution
    - But also comes up with a cons of our competitor might start offering managed offering of the project itself if they identify us early.

- Lakehouse dump in near-real-time


## Framework feature

- Testing support
    - Normal sync tests
    - connection check for different flavours of DBs
    - Benchmark integration testing

- Logging

- Lakehouse utilities like reading schema from Lakehouses

- Version updates (May be migration)

- State, schema & spec saves

- Parallel loading & Horizontal scaling (Managed offering)

- CLI, API & UI

## Distribution:

- As simple as running a docker compose.

- CLI is preferred for v0 but next versions will have UI.

- AWS and SaaS offering, Iceberg lakes + Open Source

## Assumptions :

We should only go for Lakehouses. No other destinations.

- This will save us from maintaining too many connectors for destinations.
- Most popular warehouses can directly query Apache Iceberg/ Apache Hudi
- 56% share is of Lakehouses & increasing. (stats, stats)

We will start with MongoDB

- Eventually will have to add Kafka
- We might nee to decide if PG & Mysql need to be added if demand comes

## Destination:

V0: AWS S3 in iceberg (Glue catalog) - Stringified data and Level 1 flattening

## Source:

- Any MongoDB
- Kafka/Postgres/Mysql
- Operational databases as sources