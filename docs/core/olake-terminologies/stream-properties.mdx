---
title: Streams Properties
description: Streams Properties Description
sidebar_position: 2
---

## Normalization

Normalization in OLake is the transformation step that converts raw, semi-structured change events from source drivers into structured, relational streams that are ready to be written into Iceberg/Parquet tables. 
- Detects schema evolution (adds, drops, type promotions) and writes according to Iceberg v2 spec.
- Flattens nested structures so records become query-friendly.
- Focuses on mapping source types to Iceberg/Parquet types.

*For input as given below,*
<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/normalization.png" 
       alt="Olake Partition"
       style={{ width: "100%", maxWidth: "700px" }} />
</div>

\
**Queried using AWS Athena** \
*Initial state: Sync done, when normalization is off. Focus on the data column.*
<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/norm-off.gif" 
       alt="Olake Partition output"
       style={{ width: "100%", maxWidth: "850px" }} />
</div>

*After state: Sync done, when normalization is on.*
<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/norm-on.gif" 
       alt="Olake Partition output"
       style={{ width: "100%", maxWidth: "850px"}} />
</div>

**Advantages:**
- Normalized streams can be queried with standard SQL—no unusual parsing or UDFs needed.
- Schema evolution (adds/drops/type promotions) is detected and written per Iceberg v2 spec, so downstream tables continue to operate without pipeline breaks as source schemas evolve.
- With transformation and normalization integrated into the pipeline (before the write) mean no extra post-processing jobs, so no extra Spark/DBT/Glue jobs later to "fix" the shape is required.

---

## Sync Modes

Sync modes in Olake define the strategy used to replicate data from a source system to a destination. Each mode represents a different approach to data synchronization, with specific behaviours, guarantees, and performance characteristics.

OLake supports 4 distinct sync modes:

1. **Full Refresh:**  
    Entire table is re-copied from source to destination in parallel chunks. Useful as a main sync mode or for initial loads.

2. **CDC (Change Data Capture):**  
    Real-time replication that first does an optional backfill, then streams changes (inserts, updates, deletes) in real-time. Two phases: PreCDC (initialization) and PostCDC (shutdown).

3. **Incremental:**  
    A delta-sync strategy that only processes new or changed records since the last sync. Requires primary and secondary cursor fields for change detection. Includes backfill when needed.
    :::info
    Cursor fields refer to the columns in the source table that can be used to determine the "position" of the last synced records. As of now, user can set 2 cursor fields, primary and secondary in Olake.
    :::

4. **Strict CDC:**  
    A CDC variant that skips backfill entirely, focusing on only processing changes occurring after CDC begins.

<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/sync-modes.png" 
       alt="Olake Partition output"
       style={{ width: "100%", maxWidth: "700px" }} />
</div>

---

## Data Filter

The data filter feature allows selective ingestion from source databases by applying SQL-style `WHERE` clauses or BSON-based conditions during ingestion.

- Ensures only relevant data enters the pipeline, saving on transfer, storage, and processing.
- Supports combining up to two conditions with logical operators (AND/OR).
- Operators: `>`, `<`, `=`, `!=`, `>=`, `<=`
- Values can be `numbers`, `quoted strings/timestamps/ids (eg.created_at > \"2025-08-21 17:38:35.017\")`, or `null`.

**Adoption of filter in drivers:**
- **Postgres:** During chunk processing, filters are applied alongside chunk conditions, ensuring only matching records are ingested—even with CTID-based chunking.
- **MySQL:** During chunk processing, filters are applied within each chunk so only relevant rows are returned, even with limit-offset chunking.
- **MongoDB:** During chunk processing, filters are enforced in the aggregation pipeline’s $match stage to ensure only compliant documents are processed.
- **Oracle:** Similar to Postgres and MySQL, filters are applied within each chunk’s scan, guaranteeing only records satisfying conditions are ingested.

<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/data-filter.png" 
       alt="Olake Partition output"
       style={{ width: "100%", maxWidth: "550px" }} />
</div>

---

## Schema

The schema refers to the schematics of streams which was generated by Olake, during discover processing of the source. \
The ability to adjust a schema (add/remove columns, change types) without rewriting the entire table is called `Schema Evolution`. \
*Usage: If a product table adds a new category field, a schema-evolved table format like Iceberg can incorporate this new column on the fly.*

For more information, refer to [Schema Evolution Feature](/docs/writers/features/schema)

<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/schema.png" 
       alt="Olake Partition output"
       style={{ width: "100%", maxWidth: "650px" }} />
</div>

---

## Partitioning

Partitioning organizes data by grouping similar rows based on column values or transformations, enabling efficient query processing and data management. In simple terms, routes output by record values. The result is fewer data files scanned, less I/O, and faster queries. 

:::info
Unlike traditional systems like Hive, Iceberg's approach uses "hidden partitioning," where partition details are managed in metadata rather than physical folders or explicit columns.
:::

- **Usage Format:**  `"partition_regex" = "/{field_name, transform}/{next_field, transform}"` \
  Example:-
    - Partition Regex : `"/{created_at, day}"` => Partitioning done on the `created_at` field, transformed using 'day'.

*For input as given below,*
<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/partition.png" 
       alt="Olake Partition"
       style={{ width: "100%", maxWidth: "700px" }} />
</div>

*As seen below, partition on created_at field, tranformation using 'day' has been done.*
<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/partition-output.png" 
       alt="Olake Partition output"
       style={{ width: "100%", maxWidth: "750px" }} />
</div> 

\
**Benefits of Partitioning:**
- **Faster Data Retrieval:** Queries filtering on partitioned columns (e.g., time ranges) only scan relevant partitions, avoiding full table scans. For instance, in a logs table partitioned by date, a query for a specific day skips files from other dates, potentially speeding up results by orders of magnitude for large tables.
- **Automatic Partition Pruning:** In case of Iceberg, it derives partition filters from logical predicates without requiring users to add extra filters, unlike Hive where missing partition conditions lead to scanning all data. This can improve query times by 50% or more in real-world scenarios, such as financial data analysis. This feature is vital for streaming logs, e-commerce orders, or IoT telemetry etc.
- **Efficient Handling of High-Volume Data:** For high-cardinality fields (e.g., user IDs), transforms like bucketing distribute data evenly, preventing hotspots and enabling balanced query loads. Combined with sorting within partitions, this further optimizes scans by leveraging min/max statistics in file footers. For example, using `“/{user_id, bucket[512]}"`, will hash user_id and assign it to buckets ranging from 0 - 511. 
- **Diverse Transforms:** Supports flexible operations like identity, year/month/day/hour extraction, bucketing, and truncation, enabling tailored partitioning for various use cases (e.g., time-series data or categorical grouping). For example, bucketing high-cardinality keys like UUIDs into fixed groups improves write distribution and query efficiency.
- **Schema Independence:** Partitioning isn't tied to the table's schema, so you can evolve schemas (e.g., add columns) without breaking partitioning or queries.
- **Hidden Partitioning:** Writers don't need to manually compute or supply partition values; For example, in Iceberg derives them from source columns (e.g., converting a timestamp to a date). This avoids silent errors like incorrect formats or time zones (common in Hive).

---

## Job Configuration

The job configuration property refers to the options that defines job’s name, schedule, and execution in the Olake’s system. \
User has to start with job creation, which will be followed with source configuration, then destination configuration, checking and enabling relevant tables from the schema for sync, and then finally in job configuration,  job name and frequency has to be set.

- **Frequency Options:**  
  - Default options i.e every minute, hourly, daily, weekly
  - Custom frequency: Specify a cron expression.

**Guide to Cron Expression:**

| * | * | * | * | * |
|---|---|---|---|---|
| minute (0-59) | hour (0-23) | day of the month (1-31) | month (1-12) | day of the week (0-6) |


**Cron Examples:**
- `* * * * *` = Every minute
- `0 * * * *` = Every hour
- `0 0 * * *` = Every day at 12:00 AM
- `0 0 * * FRI` = At midnight only on Fridays
- `0 0 1 * *` = At midnight on the 1st day of each month

<div style={{ textAlign: "center" }}>
  <img src="/img/docs/terminologies/job-config.png" 
       alt="Olake Partition output"
       style={{ width: "100%", maxWidth: "1000px" }} />
</div>
