---
title: Partitioning
description: How to configure and use Apache Iceberg partitioning in OLake's Iceberg writer, with clear examples and links to upstream docs.
sidebar_position: 6
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<style>
{`
/* Consistent styling for docs */
.center-image {
  text-align: center;
  margin: 20px 0;
}
.center-image img {
  max-width: 100%;
  height: auto;
  display: block;
  margin: 0 auto;
}

.full-width-container {
  width: 100% !important;
  max-width: 100% !important;
}

.full-width-container img {
  width: 100% !important;
  max-width: 100% !important;
  height: auto;
}

.full-width-table {
  width: 100% !important;
  max-width: 100% !important;
  overflow-x: auto;
}

.full-width-table table {
  width: 100% !important;
  max-width: 100% !important;
  table-layout: auto;
  margin: 0 !important;
}

.full-width-table th,
.full-width-table td {
  padding: 8px 12px;
  word-wrap: break-word;
}

.markdown table {
  width: 100% !important;
  max-width: 100% !important;
  display: table !important;
}

.table-wrapper {
  width: 100% !important;
  max-width: 100% !important;
}

.full-width-table * {
  max-width: 100% !important;
}

div[class*="table"] table,
.markdown > table,
table {
  width: 100% !important;
  max-width: 100% !important;
}
`}
</style>

# Iceberg Partitioning Support

Partitioning groups rows that share common values at **write-time**, so that queries filtering on those values read only the relevant files. The result is **fewer data files scanned, less I/O, and faster queries**.

OLake allows seamless writing into **partitioned Iceberg tables**, supporting all built-in transformations in **Apache Iceberg™**.

### How Iceberg Handles Partitions?

Apache Iceberg stores partition data in both its metadata and manifest files to enable **efficient querying** and **file pruning**. Rather than embedding partition information in file paths, Iceberg records the partition values for each file in manifests and maintains a snapshot-based metadata tree that tracks those manifests.

When you run a query like `WHERE date > …`, Iceberg consults the metadata to skip over any data files whose recorded partition values cannot satisfy the filter.

#### Key Features
- Hidden partitioning
- Evolvable specs
- Rich partition transforms
- Manifest metadata
- Snapshot isolation
- Efficient pruning

Learn more about [Iceberg Partitioning](https://iceberg.apache.org/docs/1.7.2/partitioning/).

### How to Add a Partition in OLake?

When adding a partition, you need to configure two components:

<div className="full-width-table">

| Component      | Meaning                                                            |
|----------------|--------------------------------------------------------------------|
| **field_name**   | Column in the table (**created_at**, **user_id**, etc.)            |
| **transform**    | Iceberg transform that converts the value, e.g., **identity**      |


</div>

<br></br>

**Example 1: Time-based partitioning for event data**
```
/{event_date, day}/{event_hour, hour}
```
- Partitions data by day and hour for efficient time-range queries
- Useful for analytics workloads with time-based filtering

**Example 2: Geographic and temporal partitioning**
```
/{region, identity}/{created_at, month}
```
- Partitions by geographic region and creation month
- Ideal for multi-region applications with time-based analysis

Check all the available transforms [below](#supported-transformations).

### Configuration

<Tabs>

<TabItem value="ui" label="OLake UI" default>

1. After configuring your source and destination, navigate to the **Streams Selection** page.
2. Select your table.
3. Keep **Normalization** enabled.
4. Select **Partitioning** in the right tab.
5. Add your **partition field** along with the **transform**.

<div className="center-image">

![Partitioning OLake UI](/img/docs/iceberg/partitioning-olake-ui.png)

</div>

</TabItem>

<TabItem value="cli" label="OLake CLI">

### Configure Partitioning in `streams.json`

After running the **discover** and **sync** commands, update the **partition_regex** field in your **streams.json** file to add your **partition field** and **transform**:

```json title="streams.json"
{
  "selected_streams": {
    "my_namespace": [
      {
        "stream_name": "my_stream",
        "partition_regex": "/{created_at, year}",
        "normalization": true
      }
    ]
  }
}
````

</TabItem>

</Tabs>

For hierarchical partitioning, you can have multiple `/{field_name, transform}` entries in the **Partition regex**.
Example: `/{created_at, year}/{user_id, bucket[32]}`

:::info Special case
You may use `now()` as a pseudo-column that evaluates to the **_olake_timestamp** column which is the writer's current timestamp (useful when your records lack a suitable time field).
:::

### Supported Transformations

All transforms create partition folders with predictable naming patterns for efficient querying:

| Transform         | How It Works                                          | Spec Snippet             | Example Input → Partition Value                                |
| ----------------- | ----------------------------------------------------- | ------------------------ | -------------------------------------------------------------- |
| **`identity`**    | Writes the raw value unchanged                        | `/{status, identity}`    | `status = 'active'` → folder `status=active/`                  |
| **`year`**        | Extracts calendar year as years since 1970            | `/{created_at, year}`    | `created_at = 2025-04-24 15:42` → `created_at_year=55/`        |
| **`month`**       | Extracts month as months since 1970-01-01 (integer)   | `/{created_at, month}`   | `created_at = 2025-04-24 15:42` → `created_at_month=664/`      |
| **`day`**         | Extracts the date as days since epoch (1970-01-01)    | `/{event_date, day}`     | `event_date = 2025-04-24` → `event_date_day=20202/`            |
| **`hour`**        | Extracts timestamp as hours since 1970-01-01 00:00:00 | `/{event_time, hour}`    | `event_time = 2025-04-24 15:42` → `event_time_hour=484863/`    |
| **`bucket[N]`**   | Hashes the value into **N** numbered buckets (0…N-1)  | `/{user_id, bucket[64]}` | `user_id = 'f47ac10b...'` → `user_id_bucket=17/` *(one of 64)* |
| **`truncate[N]`** | Keeps the first **N** UTF-8 characters                | `/{domain, truncate[4]}` | `domain = 'example.com'` → `domain=exam/`                      |
| **`void`**        | Always produces null values                           | `/{old_field, void}`     | `old_field = 'any_value'` → `old_field=null/`                  |

:::info Void Transform and Non-Linear Transformations
The **void transform** in Apache Iceberg always produces null values regardless of input. It effectively **drops** a partition field without removing it from the partition specification. Starting from Iceberg V2, it is used when dropping a partition field.

**Non-linear transformations** like `bucket` and `void` do not preserve ordering, meaning there's no predictable relationship between input values and their transformed output positions.
:::

:::warning Important
Iceberg does not support redundant fields during partitioning, even with different transforms on the same column. Avoid applying multiple time transforms to the same column in a single partition specification.

**Redundant transform combinations:**

* `year(ts)` is redundant with `month(ts)`, `hour(ts)`, `day(ts)`
* `month(ts)` is redundant with `hour(ts)` and `day(ts)`
* `day(ts)` is redundant with `hour(ts)`

For example, this is incorrect: **`/{timestamp_col, hour}/{timestamp_col, minute}`**
:::
