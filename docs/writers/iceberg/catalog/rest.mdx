---
title: 2. REST
description: OLake Apache Iceberg writer description
sidebar_position: 2
---

## REST Catalog

The REST catalog is a standardized API designed to simplify the management of Apache Iceberg tables across diverse engines and programming languages. By providing a unified client interface, it eliminates the need for separate catalog integrations for engines like Spark, Flink, Trino, or languages like Java. 

Built on an OpenAPI specification, the REST catalog offers a modern, flexible alternative to the Hive Metastore’s Thrift interface, tailored specifically for Iceberg’s architecture.



<Tabs queryString="rest-catalog">
<TabItem value="generic" label="Generic" default>

The Generic **REST Catalog** is the default implementation of the Apache Iceberg REST Catalog API. 
It provides a standard, engine-agnostic way to manage Iceberg tables without depending on a specific catalog service like Nessie, Polaris, or Unity.

This guide helps you set up and use Tabular REST as an Iceberg REST catalog with OLake.

### Prerequisites
1. Docker is installed and running on your machine.

2. Required services:
- **Object store (warehouse)** – e.g., S3, MinIO, or another S3-compatible storage for table data and metadata.
- **Metadata database** – typically PostgreSQL, with a dedicated database and user for Iceberg.
- **REST service** – the iceberg-rest container or equivalent, configured with warehouse + DB connection.

:::note
All services involved in the sync OLake, REST Catalog Service, MinIO, and Postgres must run in the **same Docker network**.
:::

<br />

### Environment Setup

Save the following `docker-compose.yml` which will start the following services required for an Iceberg REST Catalog.

1. **REST Catalog Service** (Tabular image) – Provides the REST API for managing Iceberg tables.
2. **PostgreSQL** – Serves as the metadata database to track Iceberg table metadata and schema evolution.
3. **MinIO + MinIO Client** – An S3-compatible object store used to store table data and snapshots.

```yml title="docker-compose.yml"
version: "3.9"

services:
  rest:
    image: tabulario/iceberg-rest
    container_name: iceberg-rest
    ports:
      - 8181:8181
    volumes:
      - catalog-data:/catalog
    environment:
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password
      AWS_REGION: us-east-1
      CATALOG_WAREHOUSE: s3://warehouse/
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      CATALOG_S3_ENDPOINT: http://minio:9090
      CATALOG_URI: jdbc:postgresql://postgres:5432/iceberg
      CATALOG_JDBC_USER: iceberg
      CATALOG_JDBC_PASSWORD: password
    networks:
      - iceberg_net
    depends_on:
      postgres:
        condition: service_healthy
      mc:
        condition: service_completed_successfully

  postgres:
    image: postgres:15
    container_name: postgres
    networks:
      - iceberg_net
    environment:
      POSTGRES_USER: iceberg
      POSTGRES_PASSWORD: password
      POSTGRES_DB: iceberg
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "iceberg", "-d", "password" ]
      interval: 2s
      timeout: 10s
      retries: 3
      start_period: 10s
    ports:
      - 5432:5432
    volumes:
      - ./data/postgres-data:/var/lib/postgresql/data

  minio:
    image: minio/minio
    hostname: minio
    container_name: minio
    ports:
      - 9090:9090
      - 9091:9091
    volumes:
      - minio-data:/data
    environment:
      MINIO_ACCESS_KEY: admin
      MINIO_SECRET_KEY: password
      MINIO_DOMAIN: minio
    command: server --address ":9090" --console-address ":9091" /data
    networks:
      iceberg_net:
        aliases:
          - warehouse.minio

  mc:
    image: minio/mc
    container_name: mc
    environment:
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password
      AWS_REGION: us-east-1
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc alias set minio http://minio:9090 admin password) do echo '...waiting...' && sleep 1; done;
      echo 'Ensuring warehouse bucket exists and is public...';
      if /usr/bin/mc stat minio/warehouse > /dev/null 2>&1; then
        echo 'Warehouse bucket exists, removing for fresh start...';
        /usr/bin/mc rm -r --force minio/warehouse || echo 'Failed to remove warehouse, proceeding...';
      fi;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc anonymous set public minio/warehouse;
      echo 'Minio warehouse bucket setup complete.';
      "
    networks:
      - iceberg_net
    depends_on:
      - minio

volumes:
  catalog-data:
  minio-data:

networks:
  iceberg_net:
```

Start the services:

```bash
docker-compose up -d
```

<br />

### Configuration
  <Tabs>
    <TabItem value="rest-ui" label="OLake UI" default>

    In the OLake UI, go to the **Destinations** page and click **+ Create Destination**. From the list of connectors, choose **Iceberg**. In the configuration form that appears, select **REST** as the catalog type and fill in the required details.
    
    <div className='flex justify-center w-2/3 mx-auto'>
      ![Create Destination](/img/docs/iceberg/catalog/rest/rest-config.jpeg)
    </div>
    - <RESTIcebergWriterUIConfigDetails />
    <br />

    ### Querying Data
    Once the data is synced successfully, you can query the Iceberg tables from any supported query engine using the following query:
    <CatalogQuery />  
    </TabItem>

    <TabItem value="jdbc-cli" label="OLake CLI">
    <RESTIcebergWriterConfig />
    - <RESTIcebergWriterConfigDetails />

    ### Querying Data
    Once the data is synced successfully, you can query the Iceberg tables from any supported query engine using the following query:
    <CatalogQuery />

    </TabItem>

  </Tabs>

</TabItem>

<TabItem value="lakekeeper" label="Lakekeeper">

  Lakekeeper is a service that provides a unified view of all your data lakes, regardless of their location. It allows you to manage and monitor your data lakes from a single interface, making it easier to keep track of your data and ensure its integrity.

  We have provided a sample configuration for Lakekeeper, which can be used to set up the service in your environment. This configuration includes all the necessary parameters and settings to get started with Lakekeeper. Reder [here](https://docs.lakekeeper.io/getting-started/) for more

  After you have set up Lakekeeper using the docker compose provided, you can access the Lakekeeper UI at `http://localhost:8181/ui`.

  <h4 id="steps-to-create-a-warehouse-in-lakekeeper">Steps to create a Warehouse in Lakekeeper</h4>

  1. **Access the Warehouse Section:**

    - Navigate to the `Warehouse` section within Lakekeeper.

  2. **Initiate Warehouse Creation:**

    - Click on the `Add Warehouse` button.

  3. **Select the Storage Type:**

    - Choose `S3` as the storage option.

  4. **Enter AWS Credentials:**

    - Provide the AWS Access Key ID as `admin`.
    - Provide the AWS Secret Access Key as `password`.

  5. **Configure S3 Settings:**

    - Set the S3 Flavor to `S3 Compatible Storage`.
    - Enable the toggle for `Enable path style access`.
    - Enable the toggle for `Enable alternative s3 protocols`.

  6. **Specify the Bucket Details:**

    - Enter the bucket name as `warehouse` (or the name of the bucket you created using MinIO).

  7. **Configure the Endpoint:**

    - Provide the endpoint as `http:{IP of your machine}:9000`.
    - To retrieve your machine's IP address, execute the command:
      ```
      ipconfig getifaddr en0
      ```

  8. **Select the Bucket Region:**
    - Choose the appropriate region for your bucket.

  Following these steps will successfully create a warehouse in Lakekeeper.

</TabItem>

<TabItem value="nessie" label="Nessie">

The **REST Nessie Catalog** integrates [Project Nessie](https://projectnessie.org/) as the catalog for Apache Iceberg using the REST Catalog API.

Unlike the Generic REST Catalog, Nessie adds Git-like version control for data, enabling branching, tagging, and reproducible queries across multiple engines.

### Prerequisites
1. Docker is installed and running on your machine.
2. Required services:
- **Object store (warehouse)** – e.g., S3, MinIO, or another S3-compatible storage for table data and metadata.
- **Metadata database** – typically PostgreSQL, with a dedicated database and user for Iceberg + Nessie.
- **Nessie REST Service** – the `projectnessie/nessie` container, which provides the catalog API and versioning features.

:::note
All services involved in the sync — OLake, Nessie, MinIO, and Postgres — must run in the **same Docker network**.
:::

<br/>


### Environment Setup
Save the following as `docker-compose.yml`: which will start the services required for a Nessie REST Catalog:
1. **Nessie REST Service** – Provides the REST API for managing Iceberg tables with version control.
2. **PostgreSQL** – Stores Nessie’s metadata and catalog state.
3. **MinIO + MinIO Client** – An S3-compatible object store used to store table data and snapshots.

```yml title="docker-compose.yml"
services:
  nessie:
    image: ghcr.io/projectnessie/nessie:latest
    container_name: nessie
    ports:
      - "19120:19120"
    environment:
      - nessie.version.store.type=JDBC
      - quarkus.datasource.db-kind=postgresql
      - quarkus.datasource.jdbc.url=jdbc:postgresql://postgres:5432/nessie_db
      - quarkus.datasource.username=nessie
      - quarkus.datasource.password=nessie
      - nessie.catalog.default-warehouse=warehouse
      - nessie.catalog.warehouses.warehouse.location=s3://warehouse/
      - nessie.catalog.service.s3.default-options.region=us-east-1
      - nessie.catalog.service.s3.default-options.path-style-access=true
      - nessie.catalog.service.s3.default-options.endpoint=http://minio:9000/
      - nessie.catalog.service.s3.default-options.external-endpoint=http://localhost:9000/
      - nessie.catalog.service.s3.default-options.access-key=urn:nessie-secret:quarkus:nessie.catalog.secrets.access-key
      - nessie.catalog.secrets.access-key.name=minio
      - nessie.catalog.secrets.access-key.secret=minio123
    depends_on:
      postgres:
        condition: service_healthy
      mc:
        condition: service_completed_successfully
    networks:
      - nessie-network

  minio:
    image: quay.io/minio/minio:RELEASE.2025-07-18T21-56-31Z
    container_name: minio
    ports:
      - "9000:9000"
      - "9090:9090"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
      MINIO_ADDRESS: ":9000"
      MINIO_CONSOLE_ADDRESS: ":9090"
    volumes:
      - minio-data:/data
    command: server /data
    networks:
      - nessie-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/minio/health/live || exit 1"]
      interval: 5s
      timeout: 2s
      retries: 15

  mc:
    image: quay.io/minio/minio:RELEASE.2025-07-18T21-56-31Z
    container_name: mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: /bin/bash
    restart: "no"
    command: >
      -c "mc alias set myminio http://minio:9000/ minio minio123 && 
           mc mb myminio/warehouse --ignore-existing"
    networks:
      - nessie-network

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: nessie
      POSTGRES_PASSWORD: nessie
      POSTGRES_DB: nessie_db
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/data
    networks:
      - nessie-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nessie"]
      interval: 5s
      timeout: 2s
      retries: 10

volumes:
  minio-data:
  postgres-data:

networks:
  nessie-network:
    driver: bridge
```

Start the services:

```bash
docker-compose up -d
```

<br />

### Configuration

<Tabs>

<TabItem value="nessie-ui" label="OLake UI" default>

In the OLake UI, go to the **Destinations** page and click **+ Create Destination**. From the list of connectors, choose **Iceberg**. In the configuration form that appears, select **REST** as the catalog type and fill in the required details.

<div className='flex justify-center w-2/3 mx-auto'>
  ![Nessie UI Configuration](/img/docs/iceberg/catalog/rest/rest-config.jpeg)
</div>

- **Nessie Configuration Parameters:**
  | Parameter        | Sample Value                               | Description                                                                                     |
  |------------------|--------------------------------------------|-------------------------------------------------------------------------------------------------|
  | REST Catalog URI | http://host.docker.internal:19120/iceberg/ | Specifies the endpoint URL for the Nessie REST catalog service that the writer will connect to. |
  | Iceberg S3 Path  | warehouse                                  | Determines the S3 path or storage location for Iceberg data in the warehouse bucket.            |
  | Iceberg Database | iceberg_db                                 | Specifies the name of the Iceberg database that will be used by the destination configuration.  |
  | S3 Endpoint      | http://host.docker.internal:9000           | Endpoint for the MinIO S3-compatible service.                                                   |
  | AWS Region       | us-east-1                                  | Specifies the AWS region associated with the S3 bucket where the data is stored.                |
  | AWS Access Key   | minio                                      | MinIO access key for authentication.                                                            |
  | AWS Secret Key   | minio123                                   | MinIO secret key for authentication.                                                            |

- **Authentication Fields (optional):**
  | Parameter                | Sample Value                        | Description                                                                                                   |
  |--------------------------|-------------------------------------|---------------------------------------------------------------------------------------------------------------|
  | Token                    | abc...xyz                           | Specifies the Bearer token sent in the Authorization header for authenticating with the REST catalog service. |
  | OAuth2 Auth URI          | https://auth.server.com/oauth/token | OAuth2 server URI for OAuth2 authentication.                                                                  |
  | REST Auth Type           | oauth2                              | Authentication type (e.g., "oauth2").                                                                         |
  | Credential (OAuth2)      | your_id:your_secret                 | Specifies the client ID and secret for OAuth2, formatted as client_id:client_secret.                          |
  | Scope (OAuth2)           | api.read api.write                  | OAuth2 scopes (space-separated).                                                                              |
  | REST Signing Name        | s3tables                            | Service name for AWS Signature V4 (e.g., "s3tables").                                                         |
  | REST Signing Region      | us-east-1                           | Region for AWS Signature V4 signing.                                                                          |
  | REST Enable Signature V4 | `true`                              | Enable AWS Signature V4 signing (boolean).                                                                    |
  | Disable Primary Keys     | `false`                             | Needed to set `true` for Databricks Unity Catalog as it doesn't support identifier fields                     |

<br/>

### Querying Data

Once the data is synced successfully, you can query the Iceberg tables from any supported query engine using the following query:

<CatalogQuery />

</TabItem>

<TabItem value="nessie-cli" label="OLake CLI">

To connect to Iceberg using Nessie as the catalog, create `destination.json` with the following configuration:
```json title="destination.json"
{
  "type": "ICEBERG",
  "writer": {
    "catalog_type": "rest",
      "rest_catalog_url": "http://localhost:19120/iceberg/",
      "iceberg_s3_path": "warehouse",
      "iceberg_db": "olake_db",
      "s3_endpoint": "http://localhost:9000/",
      "aws_access_key": "minio",
      "aws_secret_key": "minio123", 
      "aws_region": "us-east-1"
  }
}
```

- #### Nessie Configuration Parameters
  | Parameter        | Sample Value                               | Description                                                                                                    |
  |------------------|--------------------------------------------|----------------------------------------------------------------------------------------------------------------|
  | catalog_type     | rest                                       | Defines the catalog type used by the writer. "rest" means the writer interacts with a RESTful catalog service. |
  | rest_catalog_url | http://localhost:19120/iceberg/            | Specifies the endpoint URL for the Nessie REST catalog service that the writer will connect to.                |
  | iceberg_s3_path  | warehouse                                  | Determines the S3 path or storage location for Iceberg data in the warehouse bucket.                           |
  | iceberg_db       | iceberg_db                                 | Specifies the name of the Iceberg database that will be used by the destination configuration.                 |
  | s3_endpoint      | http://localhost:9000/                     | Endpoint for the MinIO S3-compatible service.                                                                  |
  | aws_access_key   | minio                                      | MinIO access key for authentication.                                                                           |
  | aws_secret_key   | minio123                                   | MinIO secret key for authentication.                                                                           |
  | aws_region       | us-east-1                                  | Specifies the AWS region associated with the S3 bucket where the data is stored.                               |

- #### Authentication Fields (optional):
  | Parameter                | Sample Value                        | Description                                                                                                   |
  |--------------------------|-------------------------------------|---------------------------------------------------------------------------------------------------------------|
  | token                    | abc...xyz                           | Specifies the Bearer token sent in the Authorization header for authenticating with the REST catalog service. |
  | oauth2_uri               | https://auth.server.com/oauth/token | OAuth2 server URI for OAuth2 authentication.                                                                  |
  | rest_auth_type           | oauth2                              | Authentication type (e.g., "oauth2").                                                                         |
  | credential               | your_id:your_secret                 | Specifies the client ID and secret for OAuth2, formatted as client_id:client_secret.                          |
  | scope                    | api.read api.write                  | OAuth2 scopes (space-separated).                                                                              |
  | rest_signing_name        | s3tables                            | Service name for AWS Signature V4 (e.g., "s3tables").                                                         |
  | rest_signing_region      | us-east-1                           | Region for AWS Signature V4 signing.                                                                          |
  | rest_signing_v_4         | `true`                              | Enable AWS Signature V4 signing (boolean).                                                                    |
  | no_identifier_fields     | `false`                             | Needed to set `true` for Databricks Unity Catalog as it doesn't support identifier fields                     |

<br/>

### Querying Data

Once the data is synced successfully, you can query the Iceberg tables from any supported query engine using the following query:

<CatalogQuery />

</TabItem>

</Tabs>

</TabItem>

<TabItem value="s3-tables" label="S3 Tables">

# S3 Tables 
OLake supports S3 table (as REST catalog destination) bucket with AWS signing V4.

## Configuration
Create a json for destination config (`destination.json`)

```json
{
  "type": "ICEBERG",
  "writer": {
    "catalog_type": "rest",
    "rest_catalog_url": "https://s3tables.us-east-1.amazonaws.com/iceberg",
    "iceberg_s3_path": "arn:aws:s3tables:<REGION>:<ACCOUNT_ID>:bucket/<BUCKET_NAME>",
    "iceberg_db": "<NAMESPACE>",
    "aws_access_key": "",
    "aws_secret_key": "",
    "aws_region": "<REGION>",
    "rest_signing_name": "s3tables",
    "rest_signing_region": "<REGION>",
    "rest_signing_v_4": true
  }
}
```

## Configuration Key Details
Change the following placeholders in the above configuration with:

- `REGION` -> Region for AWS bucket and catalog
- `NAMESPACE` -> This will be your s3 table bucket namespace
- `ACCOUNT_ID` -> AWS account identifier
- `BUCKET_NAME` -> Table Bucket Name

### Authentication Fields (optional):

- `token` - Bearer token for token-based authentication
- `oauth2_uri` - OAuth2 server URI for OAuth2 authentication
- `rest_auth_type` - Authentication type (e.g., "oauth2")
- `credential` - Client secret or credential for OAuth2 (Usually id:secret)
- `scope` - OAuth2 scopes (space-separated)
- `rest_signing_name` - Service name for AWS Signature V4 (e.g., "s3tables")
- `rest_signing_region` - Region for AWS Signature V4 signing
- `rest_signing_v_4` - Enable AWS Signature V4 signing (boolean)


More details on how to configure and use the S3 writer will be available soon. In the meantime, you can refer to the [Iceberg writer documentation](../iceberg/overview) for general guidance on Iceberg integration, as the principles are similar across different storage backends.



</TabItem>

<TabItem value="unity" label="Unity">
  # Unity Catalog (Databricks)

OLake supports Databricks Unity Catalog as a REST catalog destination with token-based or OAuth2 authentication.

## Important Limitations

⚠️ **Current Unity Catalog Limitations:**
- **Append Only**: At the time of creation of this documentation, Unity Catalog only supports **Append operations** (NO updates) for Iceberg writes
- **Managed Tables**: Unity Catalog supports Iceberg writes only in its own managed Iceberg tables
- **OAuth2 Status**: Currently, Personal Access Token authentication has been tested and works well. OAuth2 is available as an alternative but is experiencing issues (receiving internal server errors from Databricks during testing)

For more details on Unity Catalog Iceberg support, refer to the [official Databricks documentation](https://docs.databricks.com/aws/en/iceberg/).

This documentation is primarily focused on creating tokens for ingesting data into Unity/Databricks managed Iceberg tables using OLake.

## Prerequisites

- Admin access to Databricks workspace
- Access to AWS S3 bucket (if using AWS for external storage)

## Setup Instructions

### Step 1: Create a New User & Token

#### Create the User

It is recommended to create a new user instead of using an existing one for security purposes.

1. Go to top right corner user section → **Settings** → **Identity and Access** → **Users (Manage)**
2. Add a new user with email address
3. Go to **Settings** → **Advanced** → **Access Control**
4. Turn on **Personal Access Tokens** if it's not already enabled
   
   ![Personal Access Tokens Settings](/img/docs/iceberg/catalog/unity/unity-catalog-personal-access-tokens.png)

5. Go to **Permissions** and add the new user to allow token generation

#### Create the Token

1. Login with the new user credentials
2. Go to **Settings** → **Developer** → **Access Tokens** → **Manage**
3. Create a new token and set the appropriate validity period
4. Copy and save the token immediately (it's only visible once)

### Step 2: Create External Location for Data Storage

1. Create a new external location as Unity Catalog Iceberg requires S3-based external storage (when using AWS).
   
   Navigate to the Catalog section and click on "Create an external location":
   
   ![Create External Location](/img/docs/iceberg/catalog/unity/unity-catalog-grant-permissions.png)

2. Follow the recommended Databricks guide to add S3 bucket storage quickly and securely.

### Step 3: Create Schema with Proper Permissions

1. Create a new schema using the storage location created in Step 2
   
   ![Create New Schema Dialog](/img/docs/iceberg/catalog/unity/unity-catalog-create-external-location.png)

2. Go to **Schema** → **Permissions**
3. Grant the following permissions to the newly created user:
   - `ALL PRIVILEGES`
   - `EXTERNAL USE SCHEMA`
   - `MANAGE`
   
   ![Grant Schema Permissions](/img/docs/iceberg/catalog/unity/unity-catalog-create-schema.png)

## Configuration

<Tabs>

<TabItem value="unity-ui" label="OLake UI" default>

Unity Catalog supports two authentication methods: **Token-based** (recommended) and **OAuth2** (alternative).

### Common Configuration Fields

These fields are required for both authentication methods:

| Parameter | Sample Value | Description |
|-----------|--------------|-------------|
| **REST Catalog URL** | `https://adb-123456789.databricks.com/api/2.1/unity-catalog/iceberg-rest` | Databricks workspace URL with Unity Catalog REST API endpoint. Use your actual workspace URL. |
| **Iceberg S3 Path (Warehouse)** | `workspace` | Name of the catalog in Unity Catalog (e.g., "workspace", "main"). This appears as `iceberg_s3_path` in JSON config. |
| **Iceberg Database** | `default` | Namespace name inside the catalog (e.g., "default", "production"). This appears as `iceberg_db` in JSON config. |
| **Normalization** | `true` | Enable data normalization for proper formatting in Unity Catalog. Recommended to keep enabled. |
| **No Identifier Fields** | `true` | Required for Unity Catalog managed Iceberg tables that don't support equality delete-based updates. Must be enabled. |

### Token-Based Authentication (Recommended)

**✅ This method has been thoroughly tested and confirmed working**

Additional field required for token-based authentication:

| Parameter | Sample Value | Description |
|-----------|--------------|-------------|
| **Token** | `dapi1234567890abcdef...` | Databricks Personal Access Token for authentication. Created in Settings > Developer > Access Tokens. |

### OAuth2 Authentication (Alternative)

⚠️ **Note**: OAuth2 authentication is currently experiencing issues with internal server errors from Databricks during testing.

Additional fields required for OAuth2 authentication:

| Parameter | Sample Value | Description |
|-----------|--------------|-------------|
| **REST Auth Type** | `oauth2` | Set authentication type to OAuth2 |
| **OAuth2 URI** | `https://adb-123456789.databricks.com/oidc/v1/token` | OAuth2 server URI for your Databricks workspace |
| **Credential** | `client_id:client_secret` | Client ID and secret in format "id:secret" |
| **Scope** | `sql offline_access` | OAuth2 scopes (space-separated) |

</TabItem>

<TabItem value="unity-cli" label="OLake CLI" default>

### JSON Configuration

Create a json for destination config (`destination.json`)

```json
{
  "type": "ICEBERG",
  "writer": {
    "catalog_type": "rest",
    "normalization": true,
    "rest_catalog_url": "https://<DATABRICK_WORKSPACE_URL>/api/2.1/unity-catalog/iceberg-rest",
    "iceberg_s3_path": "<CATALOG_NAME>",
    "iceberg_db": "<NAMESPACE>",
    "token": "<DATABRICK_USER_PERSONAL_ACCESS_TOKEN>",
    "no_identifier_fields": true
  }
}
```

### Configuration Key Details

Change the following placeholders in the above configuration with:

- `DATABRICK_WORKSPACE_URL` -> Databricks workspace URL (URL that you use to access your Databricks console)
- `CATALOG_NAME` -> Catalog name (e.g., "workspace")
- `NAMESPACE` -> Namespace name inside catalog (e.g., "default")
- `DATABRICK_USER_PERSONAL_ACCESS_TOKEN` -> Go to Settings > Developer > Create Personal Access Token
- `no_identifier_fields` -> Set to `true` (Required for environments that don't support equality delete-based updates, such as Databricks Unity managed Iceberg tables)

### OAuth2 Authentication (Alternative - Currently Having Issues)

⚠️ **Note**: OAuth2 authentication is currently experiencing issues with internal server errors from Databricks during testing. Personal Access Token authentication is recommended until these issues are resolved.

You can attempt OAuth2 authentication by modifying the configuration:

```json
{
  "type": "ICEBERG",
  "writer": {
    "catalog_type": "rest",
    "normalization": true,
    "rest_catalog_url": "https://<DATABRICK_WORKSPACE_URL>/api/2.1/unity-catalog/iceberg-rest",
    "iceberg_s3_path": "<CATALOG_NAME>",
    "iceberg_db": "<NAMESPACE>",
    "rest_auth_type": "oauth2",
    "oauth2_uri": "<OAUTH2_SERVER_URI>",
    "credential": "<CLIENT_ID>:<CLIENT_SECRET>",
    "scope": "<OAUTH2_SCOPES>",
    "no_identifier_fields": true
  }
}
```

Additional OAuth2 fields:
- `rest_auth_type` -> Set to "oauth2"
- `oauth2_uri` -> OAuth2 server URI for your Databricks workspace
- `credential` -> Client ID and secret in format "id:secret"
- `scope` -> OAuth2 scopes (space-separated)

</TabItem>

</Tabs>



## Important Notes

- **Unity Catalog Compatibility**: The `no_identifier_fields: true` setting is crucial for Unity Catalog managed Iceberg tables as they don't support equality delete-based updates
- **Normalization**: Set `normalization: true` to ensure proper data formatting for Unity Catalog
- **REST API**: Unity Catalog uses Iceberg's REST catalog API for table operations
- **Permissions**: Ensure your user or service principal has appropriate permissions on the target catalog and schema

## Troubleshooting

### Common Issues

1. **Authentication Errors**: Verify your Personal Access Token is valid and has the necessary permissions
2. **Catalog Not Found**: Ensure the catalog name exists in your Unity Catalog
3. **Schema Permissions**: Check that you have CREATE TABLE permissions on the target schema
4. **Network Access**: Verify your OLake instance can reach the Databricks workspace URL

For more general guidance on Iceberg integration, refer to the [Iceberg writer documentation](../overview). 
</TabItem>

<TabItem value="polaris" label="Apache Polaris">

This guide helps you set up and use Apache Polaris as an Iceberg REST catalog with OLake. It uses Docker to run Polaris with AWS S3 integration for metadata and data storage.

#### Assumption: 
All services involved in the sync process — including the OLake source image, Polaris, and any other dependencies — must be part of the same Docker network or accessible via network configuration.

#### Setup Steps:

1. Save the following as `docker-compose.yml`:

```yaml
services:
  polaris:
    image: apache/polaris:latest # version on date: 22 Aug 2025
    container_name: polaris
    ports:
      - "8080:8080"    # Application port
      - "8181:8181"    # API port 
      - "8182:8182"    # Management port
      - "8443:8443"    # HTTPS port
    
    # Environment variables to fix the AWS region configuration issue
    environment:
      - AWS_REGION=ap-south-1
      
      # Optional: AWS credentials (if not using IAM roles)
      # Uncomment and set these if you're not using IAM roles for authentication
      # - AWS_ACCESS_KEY_ID=your_access_key_here
      # - AWS_SECRET_ACCESS_KEY=your_secret_key_here
    networks:
      - polaris-network

networks:
  polaris-network:
    driver: bridge
```

2. Start the services:
```bash
docker-compose up -d
```

3. Get Polaris root credentials from logs:

```bash
docker logs polaris | grep "root principal credentials"
```

Look for a line similar to:
```
realm: default-realm root principal credentials: bd0b5cde9ffb3966:9c377f72a27ba22c47e26cd53423fa96
```

Extract the credentials:
- **Client ID**: `bd0b5cde9ffb3966`
- **Client Secret**: `9c377f72a27ba22c47e26cd53423fa96`

4. Get bearer token for API requests (replace `<client_id>` and `<client_secret>` with the root credential):

```bash
curl -i -X POST \
  http://localhost:8181/api/catalog/v1/oauth/tokens \
  -d 'grant_type=client_credentials&client_id=<client_id>&client_secret=<client_secret>&scope=PRINCIPAL_ROLE:ALL'
```

5. Create S3 bucket with the following policy:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
                "s3:DeleteObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::your-bucket-name",
                "arn:aws:s3:::your-bucket-name/*"
            ]
        }
    ]
}
```

6. Create IAM role for S3 access. After creating the IAM role, you'll get an ARN that looks like:
```
arn:aws:iam::############:role/olake-role
```
Copy this ARN as you'll need it in the next step.

7. Create catalog (replace `<bearer_token>` with token received in prev steps, `your-bucket-name` with your S3 bucket, and `<your-iam-role-arn>` with the ARN from step 6):

```bash
curl -i -X POST http://localhost:8181/api/management/v1/catalogs \
  -H "Authorization: Bearer <bearer_token>" \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "name": "olake_catalog",
    "type": "INTERNAL",
    "properties": {
      "default-base-location": "s3://your-bucket-name"
    },
    "storageConfigInfo": {
      "storageType": "S3",
      "roleArn": "<your-iam-role-arn>",
      "allowedLocations": ["s3://your-bucket-name"]
    }
  }'
```

8. Create user and assign roles (replace `<bearer_token>` with your bearer token). The create user command’s response includes the new user’s client credentials.

```bash
# Create user (output includes client_id and client_secret, note them required in olake configuration)
curl -i -X POST "http://localhost:8181/api/management/v1/principals" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"name": "olake_user", "type": "user"}'

# Create principal role
curl -i -X POST "http://localhost:8181/api/management/v1/principal-roles" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"principalRole": {"name": "olake_user_role"}}'

# Assign role to user
curl -i -X PUT "http://localhost:8181/api/management/v1/principals/olake_user/principal-roles" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"principalRole": {"name": "olake_user_role"}}'

# Create catalog role
curl -i -X POST "http://localhost:8181/api/management/v1/catalogs/olake_catalog/catalog-roles" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"catalogRole": {"name": "olake_catalog_role"}}'

# Assign catalog role to principal role
curl -i -X PUT "http://localhost:8181/api/management/v1/principal-roles/olake_user_role/catalog-roles/olake_catalog" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"catalogRole": {"name": "olake_catalog_role"}}'

# Grant privileges
curl -i -X PUT "http://localhost:8181/api/management/v1/catalogs/olake_catalog/catalog-roles/olake_catalog_role/grants" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"grant": {"type": "catalog", "privilege": "CATALOG_MANAGE_CONTENT"}}'
```

#### Polaris Catalog Configuration in OLake

To make OLake use Polaris as the catalog, point OLake to the REST endpoint provided by Polaris (`http://host.docker.internal:8181/api/catalog`) and configure OAuth2 authentication.
<Tabs>

<TabItem value="olake-ui" label="OLake UI" default>

| Parameter            | Sample Value                                              | Description                                                                                   |
|----------------------|----------------------------------------------------------|-----------------------------------------------------------------------------------------------|
| Catalog Type         | rest                                                     | Defines the catalog type used by the writer.                                                  |
| REST Catalog URL     | http://host.docker.internal:8181/api/catalog             | Endpoint URL for the Polaris REST catalog service.                                            |
| Iceberg S3 Path      | olake_catalog                                            | S3 path or storage location for Iceberg data.                                                 |
| Iceberg Database     | olake_db                                                 | Name of the Iceberg database used by the destination configuration.                           |
| Authentication Type  | oauth2                                                   | Type of authentication (e.g., "oauth2").                                                      |
| OAuth2 URI           | http://host.docker.internal:8181/api/catalog/v1/oauth/tokens | OAuth2 server URI for authentication.                                             |
| Credential           | `<olake_user_client_id>:<olake_user_client_secret>`        | OAuth2 client ID and secret, formatted as client_id:client_secret.                            |
| Scope                | PRINCIPAL_ROLE:ALL                                       | OAuth2 scopes (space-separated).                                                              |
| AWS Region           | ap-south-1                                               | AWS region associated with the S3 bucket.                                                     |

</TabItem>

<TabItem value="olake-cli" label="OLake CLI">
**Example: `writer.json`**
Save the following as `writer.json`, replacing `<olake_user_client_id>` and `<olake_user_client_secret>` with the credentials from the create user response:

```json
{
    "type": "ICEBERG",
    "writer": {
      "catalog_type": "rest",
      "rest_catalog_url": "http://host.docker.internal:8181/api/catalog", 
      "iceberg_s3_path": "olake_catalog",
      "iceberg_db": "olake_db",
      "rest_auth_type": "oauth2",
      "oauth2_uri": "http://host.docker.internal:8181/api/catalog/v1/oauth/tokens",
      "credential": "<olake_user_client_id>:<olake_user_client_secret>",
      "scope": "PRINCIPAL_ROLE:ALL",
      "aws_region": "ap-south-1"
    }
}
```

</TabItem>

</Tabs>

**Important Notes:**
- Use the `olake_user` credentials (not root credentials) for the final OLake configuration.
- The IAM role ARN is required for S3 access permissions.
- Ensure your AWS region matches across all configurations.

</TabItem>

<TabItem value="gravitino" label="Gravitino">

Coming soon!

</TabItem>

</Tabs>
