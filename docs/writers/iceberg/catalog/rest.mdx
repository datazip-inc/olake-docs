---
title: 2. REST
description: OLake Apache Iceberg writer description
sidebar_position: 2
---

## REST Catalog

<Tabs>

<TabItem value="jdbc-ui" label="OLake UI" default>

<RESTIcebergWriterUIConfigDetails />

You can query the data via:

<CatalogQuery />

For S3 related permissions which is needed to write data to S3, refer to the [AWS S3 Permissions](../../parquet/partitioning) documentation.

</TabItem>

<TabItem value="jdbc-cli" label="OLake CLI" default>

<RESTIcebergWriterConfig />

### REST Configuration Parameters

<RESTIcebergWriterConfigDetails />

You can query the data via:

<CatalogQuery />

For S3 related permissions which is needed to write data to S3, refer to the [AWS S3 Permissions](../../parquet/partitioning) documentation.

</TabItem>

<TabItem value="catalog-types" label="REST Supported catalog types">

<Tabs>

<TabItem value="lakekeeper" label="Lakekeeper" default>

Lakekeeper is a service that provides a unified view of all your data lakes, regardless of their location. It allows you to manage and monitor your data lakes from a single interface, making it easier to keep track of your data and ensure its integrity.

We have provided a sample configuration for Lakekeeper, which can be used to set up the service in your environment. This configuration includes all the necessary parameters and settings to get started with Lakekeeper. Reder [here](https://docs.lakekeeper.io/getting-started/) for more

After you have set up Lakekeeper using the docker compose provided, you can access the Lakekeeper UI at `http://localhost:8181/ui`.

#### Steps to create a Warehouse in Lakekeeper

1. **Access the Warehouse Section:**

   - Navigate to the `Warehouse` section within Lakekeeper.

2. **Initiate Warehouse Creation:**

   - Click on the `Add Warehouse` button.

3. **Select the Storage Type:**

   - Choose `S3` as the storage option.

4. **Enter AWS Credentials:**

   - Provide the AWS Access Key ID as `admin`.
   - Provide the AWS Secret Access Key as `password`.

5. **Configure S3 Settings:**

   - Set the S3 Flavor to `S3 Compatible Storage`.
   - Enable the toggle for `Enable path style access`.
   - Enable the toggle for `Enable alternative s3 protocols`.

6. **Specify the Bucket Details:**

   - Enter the bucket name as `warehouse` (or the name of the bucket you created using MinIO).

7. **Configure the Endpoint:**

   - Provide the endpoint as `http:{IP of your machine}:9000`.
   - To retrieve your machine's IP address, execute the command:
     ```
     ipconfig getifaddr en0
     ```

8. **Select the Bucket Region:**
   - Choose the appropriate region for your bucket.

Following these steps will successfully create a warehouse in Lakekeeper.

</TabItem>

<TabItem value="nessie" label="Nessie">

This guide helps you set up and use Project Nessie as an Iceberg REST catalog with OLake. It uses Docker Compose to spin up Nessie, MinIO (S3-compatible object store), and Postgres (for Nessie metadata storage).

#### Assumption: 
All services involved in the sync process — including the OLake source image, Nessie, MinIO, and any other dependencies — must be part of the same Docker network.

####  Setup Steps:
1. Save the following as `docker-compose.yml`:

```yaml

services:
  nessie:
    image: ghcr.io/projectnessie/nessie:latest
    container_name: nessie
    ports:
      - "19120:19120"
    environment:
      - nessie.version.store.type=JDBC
      - quarkus.datasource.db-kind=postgresql
      - quarkus.datasource.jdbc.url=jdbc:postgresql://postgres:5432/nessie_db
      - quarkus.datasource.username=nessie
      - quarkus.datasource.password=nessie
      - nessie.catalog.default-warehouse=warehouse
      - nessie.catalog.warehouses.warehouse.location=s3://warehouse/
      - nessie.catalog.service.s3.default-options.region=us-east-1
      - nessie.catalog.service.s3.default-options.path-style-access=true
      - nessie.catalog.service.s3.default-options.endpoint=http://minio:9000/
      - nessie.catalog.service.s3.default-options.external-endpoint=http://host.docker.internal:9000/
      - nessie.catalog.service.s3.default-options.access-key=urn:nessie-secret:quarkus:nessie.catalog.secrets.access-key
      - nessie.catalog.secrets.access-key.name=minio
      - nessie.catalog.secrets.access-key.secret=minio123
    depends_on:
      postgres:
        condition: service_healthy
      mc:
        condition: service_completed_successfully
    networks:
      - nessie-network

  minio:
    image: quay.io/minio/minio:RELEASE.2025-07-18T21-56-31Z
    container_name: minio
    ports:
      - "9000:9000"
      - "9090:9090"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
      MINIO_ADDRESS: ":9000"
      MINIO_CONSOLE_ADDRESS: ":9090"
    volumes:
      - minio-data:/data
    command: server /data
    networks:
      - nessie-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/minio/health/live || exit 1"]
      interval: 5s
      timeout: 2s
      retries: 15

  mc:
    image: quay.io/minio/minio:RELEASE.2025-07-18T21-56-31Z
    container_name: mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: /bin/bash
    restart: "no"
    command: >
      -c "mc alias set myminio http://minio:9000/ minio minio123 && 
           mc mb myminio/warehouse --ignore-existing"
    networks:
      - nessie-network

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: nessie
      POSTGRES_PASSWORD: nessie
      POSTGRES_DB: nessie_db
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/data
    networks:
      - nessie-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nessie"]
      interval: 5s
      timeout: 2s
      retries: 10

volumes:
  minio-data:
  postgres-data:

networks:
  nessie-network:
    driver: bridge
```

2. Start the services:

```bash
docker-compose up -d
```

#### Nessie Catalog Configuration in OLake
To make OLake use Nessie as the catalog, you'll need to point OLake to the REST endpoint provided by Nessie (`http://host.docker.internal:19120/iceberg/`), and configure it to write data to MinIO under the warehouse bucket.

**Example: `writer.json`**
Save the following config as `writer.json` or your equivalent config file:

```json
{
  "type": "ICEBERG",
  "writer": {
    "catalog_type": "rest",
      "rest_catalog_url": "http://host.docker.internal:19120/iceberg/",
      "iceberg_s3_path": "s3://warehouse/",
      "iceberg_db": "iceberg_db",
      "s3_endpoint": "http://host.docker.internal:9000",
      "aws_access_key": "minio",
      "aws_secret_key": "minio123",
      "aws_region": "us-east-1",
      "no_identifier_fields": true
  }
}
```

</TabItem>

<TabItem value="s3-tables" label="S3 Tables">

Click [here](../s3-tables)

</TabItem>

<TabItem value="unity" label="Unity">

Click [here](../unity-catalog)

</TabItem>

<TabItem value="gravitino" label="Gravitino">

Coming soon!

</TabItem>

<TabItem value="polaris" label="Apache Polaris">

This guide helps you set up and use Apache Polaris as an Iceberg REST catalog with OLake. It uses Docker to run Polaris with AWS S3 integration for metadata and data storage.

#### Assumption: 
All services involved in the sync process — including the OLake source image, Polaris, and any other dependencies — must be part of the same Docker network or accessible via network configuration.

#### Setup Steps:

1. Save the following as `docker-compose.yml`:

```yaml
services:
  polaris:
    image: apache/polaris:latest # version on date: 22 Aug 2025
    container_name: polaris
    ports:
      - "8080:8080"    # Application port
      - "8181:8181"    # API port 
      - "8182:8182"    # Management port
      - "8443:8443"    # HTTPS port
    
    # Environment variables to fix the AWS region configuration issue
    environment:
      # AWS Region Configuration - REQUIRED to fix your error
      - AWS_REGION=ap-south-1
      
      # Optional: AWS credentials (if not using IAM roles)
      # Uncomment and set these if you're not using IAM roles for authentication
      # - AWS_ACCESS_KEY_ID=your_access_key_here
      # - AWS_SECRET_ACCESS_KEY=your_secret_key_here
    networks:
      - polaris-network

networks:
  polaris-network:
    driver: bridge
```

2. Start the services:
```bash
docker-compose up -d
```

3. Get Polaris root credentials from logs:

```bash
docker logs polaris | grep "root principal credentials"
```

Look for a line similar to:
```
realm: default-realm root principal credentials: bd0b5cde9ffb3966:9c377f72a27ba22c47e26cd53423fa96
```

Extract the credentials:
- **Client ID**: `bd0b5cde9ffb3966`
- **Client Secret**: `9c377f72a27ba22c47e26cd53423fa96`

4. Get bearer token for API requests (replace `<client_id>` and `<client_secret>` with the values from step 3):

```bash
curl -i -X POST \
  http://localhost:8181/api/catalog/v1/oauth/tokens \
  -d 'grant_type=client_credentials&client_id=<client_id>&client_secret=<client_secret>&scope=PRINCIPAL_ROLE:ALL'
```

5. Create S3 bucket with the following policy:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
                "s3:DeleteObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::your-bucket-name",
                "arn:aws:s3:::your-bucket-name/*"
            ]
        }
    ]
}
```

6. Create IAM role for S3 access. After creating the IAM role, you'll get an ARN that looks like:
```
arn:aws:iam::############:role/olake-role
```
Copy this ARN as you'll need it in the next step.

7. Create catalog (replace `<bearer_token>` with token from step 4, `your-bucket-name` with your S3 bucket, and `<your-iam-role-arn>` with the ARN from step 6):

```bash
curl -i -X POST http://localhost:8181/api/management/v1/catalogs \
  -H "Authorization: Bearer <bearer_token>" \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "name": "olake_catalog",
    "type": "INTERNAL",
    "properties": {
      "default-base-location": "s3://your-bucket-name"
    },
    "storageConfigInfo": {
      "storageType": "S3",
      "roleArn": "<your-iam-role-arn>",
      "allowedLocations": ["s3://your-bucket-name"]
    }
  }'
```

8. Create user and assign roles (replace `<bearer_token>` with your bearer token). The create user command’s response includes the new user’s client credentials.

```bash
# Create user (output includes client_id and client_secret, note them required in olake configuration)
curl -i -X POST "http://localhost:8181/api/management/v1/principals" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"name": "olake_user", "type": "user"}'

# Create principal role
curl -i -X POST "http://localhost:8181/api/management/v1/principal-roles" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"principalRole": {"name": "olake_user_role"}}'

# Assign role to user
curl -i -X PUT "http://localhost:8181/api/management/v1/principals/olake_user/principal-roles" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"principalRole": {"name": "olake_user_role"}}'

# Create catalog role
curl -i -X POST "http://localhost:8181/api/management/v1/catalogs/olake_catalog/catalog-roles" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"catalogRole": {"name": "olake_catalog_role"}}'

# Assign catalog role to principal role
curl -i -X PUT "http://localhost:8181/api/management/v1/principal-roles/olake_user_role/catalog-roles/olake_catalog" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"catalogRole": {"name": "olake_catalog_role"}}'

# Grant privileges
curl -i -X PUT "http://localhost:8181/api/management/v1/catalogs/olake_catalog/catalog-roles/olake_catalog_role/grants" \
  -H "Authorization: Bearer <bearer_token>" \
  -H "Content-Type: application/json" \
  -d '{"grant": {"type": "catalog", "privilege": "CATALOG_MANAGE_CONTENT"}}'
```

#### Polaris Catalog Configuration in OLake

To make OLake use Polaris as the catalog, point OLake to the REST endpoint provided by Polaris (`http://host.docker.internal:8181/api/catalog`) and configure OAuth2 authentication.
<Tabs>

<TabItem value="olake-ui" label="OLake UI" default>

| Parameter            | Sample Value                                              | Description                                                                                   |
|----------------------|----------------------------------------------------------|-----------------------------------------------------------------------------------------------|
| Catalog Type         | rest                                                     | Defines the catalog type used by the writer.                                                  |
| REST Catalog URL     | http://host.docker.internal:8181/api/catalog             | Endpoint URL for the Polaris REST catalog service.                                            |
| Iceberg S3 Path      | olake_catalog                                            | S3 path or storage location for Iceberg data.                                                 |
| Iceberg Database     | olake_db                                                 | Name of the Iceberg database used by the destination configuration.                           |
| Authentication Type  | oauth2                                                   | Type of authentication (e.g., "oauth2").                                                      |
| OAuth2 URI           | http://host.docker.internal:8181/api/catalog/v1/oauth/tokens | OAuth2 server URI for authentication.                                             |
| Credential           | `<olake_user_client_id>:<olake_user_client_secret>`        | OAuth2 client ID and secret, formatted as client_id:client_secret.                            |
| Scope                | PRINCIPAL_ROLE:ALL                                       | OAuth2 scopes (space-separated).                                                              |
| AWS Region           | ap-south-1                                               | AWS region associated with the S3 bucket.                                                     |

</TabItem>

<TabItem value="olake-cli" label="OLake CLI">

```json
{
    "type": "ICEBERG",
    "writer": {
      "catalog_type": "rest",
      "rest_catalog_url": "http://host.docker.internal:8181/api/catalog", 
      "iceberg_s3_path": "olake_catalog",
      "iceberg_db": "olake_db",
      "rest_auth_type": "oauth2",
      "oauth2_uri": "http://host.docker.internal:8181/api/catalog/v1/oauth/tokens",
      "credential": "<olake_user_client_id>:<olake_user_client_secret>",
      "scope": "PRINCIPAL_ROLE:ALL",
      "aws_region": "ap-south-1"
    }
}
```

</TabItem>

</Tabs>

**Important Notes:**
- Use the `olake_user` credentials (not root credentials) for the final OLake configuration.
- The IAM role ARN from step 6 is required for S3 access permissions.
- Ensure your AWS region matches across all configurations.

</TabItem>

</Tabs>

</TabItem>

</Tabs>

:::info
If you wish to test out the REST Catalog locally, you can use the [docker-compose](../docker-compose) setup. The local test setup uses Minio as an S3-compatible storage and other all [supported catalog types](../docker-compose#local-catalog--test-setup).

You can then setup local spark to run queries on the iceberg tables created in the local test setup.
:::
