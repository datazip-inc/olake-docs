---
title: 4. Hive
description: OLake Apache Iceberg writer description
sidebar_position: 4
---

## Hive Catalog

:::info
Use `iceberg_s3_path` with `s3a` prefix if your Hive is configured so. This will work for most use cases. Otherwise, use `iceberg_path` with `s3` prefix.
:::


<Tabs>

<TabItem value="hive-ui" label="OLake UI" default>

<HiveIcebergWriterUIConfigDetails/>

</TabItem>

<TabItem value="hive-cli" label="OLake CLI" default>

<HiveIcebergWriterConfig/>

### Hive Configuration Parameters

<HiveIcebergWriterConfigDetails/>


</TabItem>

</Tabs>


You can query the data via:

<CatalogQuery/>

For S3 related permissions which is needed to write data to S3, refer to the [AWS S3 Permissions](../../parquet/partitioning) documentation.

:::info
If you wish to test out the REST Catalog locally, you can use the [docker-compose](../docker-compose) setup. The local test setup uses Minio as an S3-compatible storage and other all [supported catalog types](../docker-compose#local-catalog--test-setup). 

You can then setup local spark to run queries on the iceberg tables created in the local test setup.
:::