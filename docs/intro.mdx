---
title: Introduction
description: OLake Documentation
slug: /
---


# Welcome to OLake

<h1 align="center">
    <a href="https://olake.io" target="_blank">
        <img alt="olake" src="img/logo/olake-blue.svg" width="100" height="100"/>
    </a>
    <br/>OLake
</h1>

<p align="center">Fastest open-source tool for replicating Databases to Apache Iceberg or Data Lakehouse. ⚡ Efficient, quick and scalable data ingestion for real-time analytics. Visit <a href="https://olake.io" target="_blank">olake.io</a> for the full documentation, and benchmarks</p>


## Introduction to OLake

Welcome to **OLake** – the fastest open source DB-to-Data LakeHouse pipeline designed to bring your Database (Postgres, MySQL, MongoDB, Oracle) data into modern analytics ecosystems like Apache Iceberg. 
OLake was born out of the need to eliminate the toil of one-off ETL scripts, combat performance bottlenecks, and avoid vendor lock-in with a clean, high-performing solution.

**GitHub Repository:** [https://github.com/datazip-inc/olake](https://github.com/datazip-inc/olake)  


## What is OLake?  

OLake is an **open-source tool** that brings speed, simplicity, and reliability to replicating data into **Apache Iceberg** and **Parquet Writer**. It enables seamless extraction and replication of data from transactional databases such as **PostgreSQL, MySQL, MongoDB and Oracle** into open lakehouse formats like Apache Iceberg and Parquet Writer.  
By combining **Incremental Sync** or **Change Data Capture (CDC)** with a lightweight, high-performance architecture, OLake makes it easy to keep data in sync with minimal infrastructure cost.  

This allows organizations to:  
- Replicate data at scale  
- Power near real-time analytics  
- Transform data lakes into fully functional lakehouses without the overhead of complex ETL tools  

---
## Why OLake?  

- **Fastest Path to a Lakehouse** → Achieve high throughput with **parallelized chunking** and **resumable** historical snapshots and blazing-fast incremental updates, even on massive datasets with **exactly-once** delivery.  

- **Efficient Data Capture** → Capture data efficiently with a full snapshot of your tables or collections, then keep them in sync through near real-time **CDC** using native database logs (**WAL, binlogs, oplogs**).  

- **Schema-Aware Replication** → Automatically detect schema changes to keep your pipelines consistent and reliable.  

- **Open by Design** → Store data in **open formats** like Parquet and Iceberg, enabling **engine-agnostic analytics** and eliminating vendor lock-in.  

---
## OLake Features Overview  

### Source-Level Features  

#### Supported Connectors  

- **PostgreSQL** → Supports **Full Refresh**, **Incremental Sync**, and **WAL-based Full Refresh + CDC** and **Strict CDC** (RDS, Aurora, Supabase, etc.)  
- **MySQL** → Supports **Full Refresh**, **Incremental Sync**, and **Binlog-based Full Refresh + CDC** and **Strict CDC** (MySQL RDS, Aurora, older community versions)  
- **MongoDB** → Supports **Full Refresh**, **Incremental Sync**, and **Oplog-based Full Refresh + CDC** and **Strict CDC** (sharded or replica-set clusters)  
- **Oracle** → Supports **Full Refresh** and **Incremental Sync**  

#### Optimized Chunking Strategies  

- **PostgreSQL** → CTID ranges, batch-size splits, next-query paging  
- **MySQL** → Range splits with LIMIT/OFFSET  
- **MongoDB** → Split-Vector, Bucket-Auto, Timestamp  
- **Oracle** → DBMS Parallel Execute  

---

### Destination-Level Features  

#### Supported Connectors  

- **S3 Parquet Writer** → MinIO, S3, GCS  
- **Apache Iceberg**  :

  #### Catalog Integrations  

     - AWS Glue  
     - REST Catalog (Nessie, Polaris, Unity, LakeKeeper)  
     - Hive Metastore  
     - JDBC Catalog  

     To know more, read [OLake Catalog Integration](https://docs/understanding/compatibility-catalogs).  

---

### Query Engine Compatibility  

OLake outputs are immediately queryable in any **Iceberg v2-compatible engine**, including:  

- AWS Athena  
- Trino  
- Spark  
- Flink  
- Presto  
- Hive  
- Snowflake  

 To know more, read [OLake Query Engines Compatibility](https://docs/understanding/compatibility-engines).  